{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/SeoulTechPSE/EngMath/blob/master/ch08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "Dzthx6REAOrZ",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Rendering sympy equations requires MathJax to be available within each cell output. \n",
    "# The following is a function that will make this happen for Colab.\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    \n",
    "    from sympy import init_printing\n",
    "    from sympy.printing import latex\n",
    "\n",
    "    def colab_LaTeX_printer(exp, **options):  \n",
    "        from google.colab.output._publish import javascript \n",
    "\n",
    "        url_ = \"https://colab.research.google.com/static/mathjax/MathJax.js?\"\n",
    "        cfg_ = \"config=TeX-MML-AM_HTMLorMML\" # \"config=default\"\n",
    "\n",
    "        javascript(url=url_+cfg_)\n",
    "\n",
    "        return latex(exp, **options)\n",
    "\n",
    "    init_printing(use_latex=\"mathjax\", latex_printer=colab_LaTeX_printer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qS9vSfZ3AOrh",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chapter 8. Matrices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "colab_type": "text",
    "id": "24ZPMz8YAOri",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Contents\n",
    "\n",
    "* Matrix Algebra\n",
    "* Systems of Linear Algebraic Equations\n",
    "* Rank of Matrix\n",
    "* Determinants\n",
    "* Properties of Determinants\n",
    "* Inverse of Matrix\n",
    "* Cramer's Rule\n",
    "* The Eigenvalue Problem        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$~$\n",
    "\n",
    "* Powers of Matrices\n",
    "* Orthogonal Matrices\n",
    "* Approximation of Eigenvalues\n",
    "* Diagonalization\n",
    "* LU-factorization\n",
    "* Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4272BrhAOrj",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.1 Matrix Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* A **matrix** is any rectangular array of numbers or functions\n",
    "\n",
    " >$\\begin{pmatrix}\n",
    "    a_{11} & a_{12} & \\cdots & a_{1n}\\\\ \n",
    "    a_{21} & a_{22} & \\ddots & a_{2n} \\\\ \n",
    "    \\vdots & \\ddots & \\ddots & \\vdots \\\\ \n",
    "    a_{m1} & a_{m2} & \\cdots & a_{mn}\n",
    "  \\end{pmatrix}$  \n",
    "   \n",
    "  * The numbers or functions in the array are **entries** or **elements**\n",
    "  * An $n \\times n$ matrix  is a **square** matrix of **order $n$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "colab_type": "text",
    "id": "cXFIY453AOrl",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Column** and **row vectors** are $n \\times 1$ and $1 \\times n$ matrices\n",
    "\n",
    "  >$\n",
    "  \\begin{pmatrix}\n",
    "    a_1\\\\ \n",
    "    a_2\\\\ \n",
    "    \\vdots\\\\ \n",
    "    a_n\n",
    "  \\end{pmatrix},\\;\n",
    "  \\begin{pmatrix}\n",
    "    a_1 & a_2 & \\cdots & a_n\n",
    "  \\end{pmatrix}  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Equality of Matrices** \n",
    "\n",
    "  $\\mathbf{A} = \\left(a_{ij}\\right)_{m \\times n}\\text{ }$ and $\\text{ }\\mathbf{B} = \\left(b_{ij}\\right)_{m \\times n}\\text{ }$ are *equal* $~$if $a_{ij}=b_{ij}$ for each $i$ and $j$\n",
    "  \n",
    "* **Matrix Addition**\n",
    "\n",
    "  $\\mathbf{A} +\\mathbf{B} = \\left(a_{ij} +b_{ij}\\right)_{m \\times n}$\n",
    "  \n",
    "* **Scalar Multiplication**\n",
    "\n",
    "  $k\\mathbf{A} = \\left(ka_{ij}\\right)_{m \\times n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "crV4LYHWAOrn",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Properties of Matrix Addition and Scalar Multiplication**\n",
    "\n",
    "  Suppose $\\mathbf{A}$, $\\mathbf{B}$, and $\\mathbf{C}$ are $m \\times n$ matrices and $k_1$ and $k_2$ are scalars. Then\n",
    "\n",
    "  >$\\begin{align*}\n",
    "    &\\mathbf{A} +\\mathbf{B} = \\mathbf{B} +\\mathbf{A} \\\\ \n",
    "    &\\mathbf{A} +\\left(\\mathbf{B} +\\mathbf{C}\\right) = \\left(\\mathbf{A} +\\mathbf{B}\\right) +\\mathbf{C} \\\\\n",
    "    &\\left(k_1 k_2\\right)\\mathbf{A} = k_1 \\left(k_2\\mathbf{A}\\right) \\\\\n",
    "    &k_1\\left(\\mathbf{A} +\\mathbf{B}\\right)=k_1\\mathbf{A} +k_1\\mathbf{B} \\\\\n",
    "    &\\left(k_1 +k_2\\right)\\mathbf{A} = k_1 \\mathbf{A} +k_2\\mathbf{A}  \n",
    "  \\end{align*}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbkQpqGnAOrp",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Matrix multiplication** \n",
    "  \n",
    "  >$\\displaystyle\\mathbf{A}\\mathbf{B}=\\left(\\sum_{k=1}^p a_{ik} b_{kj}\\right)_{m \\times n}$\n",
    "  \n",
    "  where $\\mathbf{A}$ is an $m \\times p$ matrix, $\\mathbf{B}$ is a $p \\times n$ matrix, and\n",
    "  $\\mathbf{A}\\mathbf{B}$ is the $m \\times n$ matrix\n",
    "  \n",
    "  * In general, $\\mathbf{A}\\mathbf{B}\\neq\\mathbf{B}\\mathbf{A}$\n",
    "  \n",
    "  * **Associative Law:** $\\mathbf{A}\\left(\\mathbf{B}\\mathbf{C}\\right)=\\left(\\mathbf{A}\\mathbf{B}\\right)\\mathbf{C}$ \n",
    "  \n",
    "  * **Distributive Law:** $\\mathbf{A}\\left(\\mathbf{B}+\\mathbf{C}\\right)=\\mathbf{A}\\mathbf{B} +\\mathbf{A}\\mathbf{C}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YvEQm1zSAOrt",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Transpose of a Matrix**\n",
    "\n",
    "  >$\\mathbf{A}^T =\n",
    "  \\begin{pmatrix}\n",
    "    a_{11} & a_{21} & \\cdots & a_{m1}\\\\ \n",
    "    a_{12} & a_{22} & \\ddots & a_{m2} \\\\ \n",
    "    \\vdots & \\ddots & \\ddots & \\vdots \\\\ \n",
    "    a_{1n} & a_{2n} & \\cdots & a_{mn}\n",
    "  \\end{pmatrix}  \n",
    "  $\n",
    "  \n",
    "* **Properties of Transpose**\n",
    "\n",
    "  >$\n",
    "  \\begin{align*}\n",
    "     &\\left(\\mathbf{A}^T\\right)^T=\\mathbf{A} \\\\ \n",
    "     &\\left(\\mathbf{A} +\\mathbf{B}\\right)^T=\\mathbf{A}^T +\\mathbf{B}^T \\\\ \n",
    "     &\\left(\\mathbf{A}\\mathbf{B}\\right)^T=\\mathbf{B}^T\\mathbf{A}^T \\\\ \n",
    "     &\\left(k\\mathbf{A}\\right)^T=k\\mathbf{A}^T\n",
    "   \\end{align*}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V2qnoQaiAOrw",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Special Matrices**\n",
    "\n",
    "  * In a **zero matrix**, all entries are zeros\n",
    "  \n",
    "  * In a **triangular matrix**, all entries above or below the main diagonal are zeros (lower triangular or upper triangular)\n",
    "  \n",
    "  * In a **diagonal matrix**, all entries not on the main diagonal are zeros\n",
    "  \n",
    "  * A **scalar matrix** is a diagonal one where all entries on the main diagonal are equal.\n",
    "    If those entries are $1$'s, it is an **identity matrix**, $\\mathbf{I}$ \n",
    "    (or $\\mathbf{I}_n$ when there ia a need to emphasize the order of the matrix)\n",
    "    \n",
    "  * An $n \\times n$ matrix $\\mathbf{A}$ is **symmetric** if $\\mathbf{A}^T=\\mathbf{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbKN9ESLAOrx",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercises 8.1\n",
    "\n",
    "* 13, 17\n",
    "* 36, 37, 39, 51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P8JeFdj0AOrz",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 8.2 Systems of Linear Algebraic Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **General Form**\n",
    "\n",
    "  A system of $m$ linear equations in $n$ unknowns has the general form\n",
    "  \n",
    "  >$\n",
    "  \\begin{align*}\n",
    "    a_{11} x_1 +a_{12} x_2 + \\cdots +a_{1n} x_n &= b_1\\\\ \n",
    "    a_{21} x_1 +a_{22} x_2 + \\cdots +a_{2n} x_n &= b_2\\\\ \n",
    "     &\\;\\;\\vdots \\\\ \n",
    "    a_{m1} x_1 +a_{m2} x_2 + \\cdots +a_{mn} x_n &= b_m\n",
    "  \\end{align*}  \n",
    "  $\n",
    "  \n",
    "  The **coefficients** of the unknowns can be abbreviated as $a_{ij}$. \n",
    "  The numbers $b_1, b_2, \\cdots, b_m$ are called the **constants** of the system. \n",
    "  If all the constants are zero, the system is said to be **homogeneous**, otherwise it is\n",
    "  **nonhomogeneous**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aQUeDgEtAOr0",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* A linear system of equations is said to be **consistent** if it has at least one solution and\n",
    "  **inconsistent** if it has no solutions. If a linear system is consistent, it has either\n",
    "  \n",
    "  * a unique solution (that is, precisely one solution), or\n",
    "  * infinitely many solutions\n",
    "\n",
    "$~$\n",
    "<img src=\"figures/ch08_figure01.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Augmented Matrix**\n",
    "\n",
    "  >$\n",
    "  \\left(\\begin{array}{cccc|c}\n",
    "    a_{11} & a_{12} & \\cdots & a_{1n} & b_1\\\\ \n",
    "    a_{21} & a_{22} & \\ddots & a_{2n} & b_2\\\\ \n",
    "    \\vdots & \\ddots & \\ddots & \\vdots & \\vdots\\\\ \n",
    "    a_{m1} & a_{m2} & \\cdots & a_{mn} & b_m\n",
    "  \\end{array}\\right)  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qr2EmQglAOr2",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* A system can be solved with **elementary operations** (**row reduction** for matrices)\n",
    "  on an augmented matrix\n",
    "  \n",
    ">| Elementary Operations | Meaning |\n",
    "|:----------------------|:--------|\n",
    "| $R_{ij}$        | Interchange rows $i$ and $j$                             |\n",
    "| $cR_{i}$        | Multiply the $i$-th row by the nonzero constant $c$      | \n",
    "| $cR_{i}+R_{j}$  | Multiply the $i$-th row by $c$ and add to the $j$-th row |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AedryhQVAOr3",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* In the **Gaussian elimination**, we row-reduce the augmented matrix until we arrive \n",
    "  at a row-equivalent augmented matrix in **row-echelon form**\n",
    "  \n",
    "  * The first nonzero entry in a nonzero row is a $1$\n",
    "\n",
    "  * In consecutive nonzero rows, the first entry $1$ in the lower row appears to the right of the $1$ in the higher row\n",
    "  \n",
    "  * Rows consisting of all zeros are at the bottom of the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example:** $\\text{ }$ Solve\n",
    "  \n",
    "  >$\n",
    "  \\begin{pmatrix}\n",
    "    2 & 6 & \\;\\; 1\\\\ \n",
    "    1 & 2 & -1\\\\ \n",
    "    5 & 7 & -4\n",
    "  \\end{pmatrix}\n",
    "  \\begin{pmatrix}\n",
    "    x_1\\\\ \n",
    "    x_2\\\\ \n",
    "    x_3\n",
    "  \\end{pmatrix}=\n",
    "  \\begin{pmatrix}\n",
    "    \\;\\;7\\\\ \n",
    "    -1\\\\ \n",
    "    \\;\\;9\n",
    "  \\end{pmatrix}  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using row operations on the augmented matrix, we obtain\n",
    "  \n",
    "  >${\\scriptsize\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    2 & 6 &  1 & 7\\\\ \n",
    "    1 & 2 & -1 & -1\\\\ \n",
    "    5 & 7 & -4 & 9\n",
    "  \\end{array}\\right) \n",
    "  \\overset{R_{12}}{\\Longrightarrow}  \n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 & -1 & -1\\\\   \n",
    "    2 & 6 &  1 & 7\\\\ \n",
    "    5 & 7 & -4 & 9\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\begin{align*}\n",
    "           -2R_1 +&R_2 \\\\ \n",
    "           -5R_1 +&R_3 \n",
    "           \\end{align*}}\n",
    "  {\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 & -1 & -1\\\\   \n",
    "    0 & 2 &  3 & 9\\\\ \n",
    "    0 & -3 & 1 & 14\n",
    "  \\end{array}\\right)} \n",
    "  $\n",
    "  \n",
    "  >${\\scriptsize\n",
    "  \\overset{\\frac{1}{2}R_2}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 & -1 & -1\\\\   \n",
    "    0 & 1 &  \\frac{3}{2} & \\frac{9}{2} \\\\\n",
    "    0 & -3 & 1 & 14\n",
    "  \\end{array}\\right)\n",
    "  \\overset{3R_2 +R_3}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 & -1 & -1\\\\   \n",
    "    0 & 1 &  \\frac{3}{2} & \\frac{9}{2} \\\\\n",
    "    0 & 0 & \\;\\frac{11}{2} & \\;\\frac{55}{2}\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\frac{2}{11}R_3}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 & -1 & -1\\\\   \n",
    "    0 & 1 &  \\frac{3}{2} & \\frac{9}{2} \\\\\n",
    "    0 & 0 & 1 & 5\n",
    "  \\end{array}\\right)}\n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWqLrPsJAOr5",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " \n",
    "  The last matrix is in row-echelon form. We can make the last matrix above to be in reduced row-echelon form\n",
    "\n",
    "  >${\\scriptsize\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 & -1 & -1\\\\   \n",
    "    0 & 1 &  \\frac{3}{2} & \\frac{9}{2} \\\\\n",
    "    0 & 0 & 1 & 5\n",
    "  \\end{array}\\right)  \n",
    "  \\overset{-2R_2 +R_1}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 0 & -4 & -10\\\\   \n",
    "    0 & 1 &  \\frac{3}{2} & \\frac{9}{2} \\\\\n",
    "    0 & 0 & 1 & 5\n",
    "  \\end{array}\\right)   \n",
    "  \\overset{\\begin{align*}\n",
    "           -4R_3 +&R_1 \\\\ \n",
    "          -\\frac{3}{2}R_3 +&R_2 \n",
    "           \\end{align*}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 0 & 0 & 10\\\\   \n",
    "    0 & 1 & 0 & -3 \\\\\n",
    "    0 & 0 & 1 & 5\n",
    "  \\end{array}\\right)} \n",
    "  $\n",
    "  \n",
    "  We see that the solution is $x_1=10$, $\\text{ }x_2=-3$, $\\text{ }x_3=5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q-_ah9OqAOr7",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example:** $\\text{ }$ Solve\n",
    "  \n",
    "  >$\n",
    "  \\left(\\begin{array}{rrr}\n",
    "    1 & 3 & -2\\\\ \n",
    "    4 & 1 & 3\\\\ \n",
    "    2 & -5 & 7\n",
    "  \\end{array}\\right) \n",
    "  \\begin{pmatrix}\n",
    "    x_1\\\\ \n",
    "    x_2\\\\ \n",
    "    x_3\n",
    "  \\end{pmatrix}=\n",
    " \\left(\\begin{array}{r}\n",
    "    -7\\\\ \n",
    "     5\\\\ \n",
    "    19\n",
    "  \\end{array}\\right)  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using row operations on the augmented matrix, we obtain\n",
    "  \n",
    "  >${\\scriptsize\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 3 & -2 & -7\\\\ \n",
    "    4 & 1 &  3 & 5\\\\ \n",
    "    2 & -5 & 7 & 19\n",
    "  \\end{array}\\right) \n",
    "  \\overset{\\begin{align*}\n",
    "           -4R_1 +&R_2 \\\\ \n",
    "           -2R_1 +&R_3 \n",
    "           \\end{align*}}\n",
    "  {\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 3 & -2 & -7\\\\ \n",
    "    0 & -11 & 11 & 33\\\\ \n",
    "    0 & -11 & 11 & 33\n",
    "  \\end{array}\\right) \n",
    "  \\overset{\\begin{align*}\n",
    "           -R_2 +&R_3 \\\\ \n",
    "           -\\frac{1}{11}&R_2 \n",
    "           \\end{align*}}\n",
    "  {\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rr:r|r}\n",
    "    1 & 3 & -2 & -7\\\\ \n",
    "    0 & 1 & -1 & -3\\\\ \\hdashline\n",
    "    0 & 0 & 0 & {\\color{Red}0 }\n",
    "  \\end{array}\\right)} \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  \n",
    "  In this case, the last matrix implies that the original system of three equations is really equivalent to\n",
    "  two equations. \n",
    "  \n",
    "  >${\\scriptsize\n",
    "  \\overset{-3R_2 +R_1}\n",
    "  {\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rr:r|r}\n",
    "    1 & 0 & 1 & 2\\\\ \n",
    "    0 & 1 & -1 & -3\\\\ \\hdashline\n",
    "    0 & 0 & 0 & 0\n",
    "  \\end{array}\\right)}   \n",
    "  $\n",
    "  \n",
    "  If we let $x_3=t$, $x_1=-t +2$ and $x_2=t -3$, then we see that the system has infinitely many solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aPa9d9zvAOr8",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example:** $\\text{ }$ Solve\n",
    "  \n",
    "  >$\n",
    "  \\left(\\begin{array}{rr}\n",
    "    1 & 1 \\\\ \n",
    "    4 & -1 \\\\ \n",
    "    2 & -3\n",
    "  \\end{array}\\right) \n",
    "  \\begin{pmatrix}\n",
    "    x_1\\\\ \n",
    "    x_2\n",
    "  \\end{pmatrix}=\n",
    " \\left(\\begin{array}{r}\n",
    "    1\\\\ \n",
    "   -6\\\\ \n",
    "    8\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Using row operations on the augmented matrix, we obtain\n",
    "  \n",
    "  >${\\scriptsize\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "    1 & 1 & 1\\\\ \n",
    "    4 & -1 & -6\\\\ \n",
    "    2 & -3 & 8\n",
    "  \\end{array}\\right) \n",
    "  \\overset{\\begin{align*}\n",
    "           -4R_1 +&R_2 \\\\ \n",
    "           -2R_1 +&R_3 \n",
    "           \\end{align*}}\n",
    "  {\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "    1 & 1 & 1\\\\ \n",
    "    0 & -5 & -10\\\\ \n",
    "    0 & -5 & 6\n",
    "  \\end{array}\\right) \n",
    "  \\overset{\\begin{align*}\n",
    "           -R_2 +&R_3 \\\\ \n",
    "           -\\frac{1}{5}R_2 \n",
    "           \\end{align*}}\n",
    "  {\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "    1 & 1 & 1\\\\ \n",
    "    0 & 1 & 2\\\\ \\hdashline\n",
    "    0 & 0 & {\\color{Red}{16}}\n",
    "  \\end{array}\\right)}  \n",
    "  $\n",
    "  \n",
    "  The system has no solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "colab_type": "text",
    "id": "KEajEf5pAOr_",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* A **homogeneous system** of linear equations is **always consistent**. The solution consisting of all zeros is called the **trivial solution**. A homogeneous system either possesses only the trivial solution or possesses the trivial solution along with infinitely many nontrivial solutions\n",
    "\n",
    "* **A homogeneous system possesses nontrivial solutions if the number $m$ of equations is less than the number $n$ of unknowns $(m<n)$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example:** $\\text{ }$ Find the positive integers $x_1$, $x_2$, $x_3$, and $x_4$ so that\n",
    "\n",
    "> $x_1 \\mathrm{C_2H_6} +x_2 \\mathrm{O_2} \\rightarrow x_3 \\mathrm{CO_2} +x_4 \\mathrm{H_2O}$\n",
    "\n",
    "Because the number of atoms of each element must be the same on each side of the last equation, we have:\n",
    "\n",
    ">| Atom |      |\n",
    "| ---- | :--- |\n",
    "|$\\mathrm{C}$ |$2x_1=x_3$       |\n",
    "|$\\mathrm{H}$ |$6x_1=2x_4$      |\n",
    "|$\\mathrm{O}$ |$2x_2=2x_3 +x_4$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6f5yFXGEAOsA",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  $${\\scriptsize\n",
    "  \\left(\\begin{array}{rrrr|r}\n",
    "    2 & 0 & -1 &  0 & 0\\\\   \n",
    "    6 & 0 &  0 & -2 & 0\\\\\n",
    "    0 & 2 & -2 & -1 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\begin{align*}\n",
    "             &R_{12} \\\\ \n",
    "             &R_{23} \n",
    "           \\end{align*}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrrr|r}\n",
    "    6 & 0 &  0 & -2 & 0\\\\\n",
    "    0 & 2 & -2 & -1 & 0\\\\\n",
    "    2 & 0 & -1 &  0 & 0  \n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr:r|r} \n",
    "    1 & 0 & 0 & -\\frac{1}{3} & 0\\\\   \n",
    "    0 & 1 & 0 & -\\frac{7}{6} & 0\\\\\n",
    "    0 & 0 & 1 & -\\frac{2}{3} & 0\n",
    "  \\end{array}\\right)}\n",
    "  $$\n",
    "  \n",
    "  Then when we let  $x_4=t$, $x_1=\\frac{1}{3}t$, $x_2=\\frac{7}{6}t$, $x_3=\\frac{2}{3}t$. If we pick $t=6$, \n",
    "  $x_1=2$, $x_2=7$, $x_3=4$, $x_4=6$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ur0f0NOAOsB",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercises 8.2\n",
    "\n",
    "* 1, 3, 5, 7, 9, 17, 19\n",
    "* 23, 25, 31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r-_MlQJ_AOsB",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.3 Rank of a Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gRRJSu_5AOsC",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The **rank** of an $m \\times n$ matrix $\\mathbf{A}$, $\\mathrm{rank}(\\mathbf{A})$, is \n",
    "  **the maximum number of linearly independent row vectors**. If a matrix $\\mathbf{A}$ is now equivalent to\n",
    "  a row-echelon form $\\mathbf{B}$, then\n",
    "\n",
    "  * the row space of $\\mathbf{A}$ = the row space of $\\mathbf{B}$\n",
    "  * the nonezero rows of $\\mathbf{B}$ form a basis for the row space of $\\mathbf{A}$, and\n",
    "  * $\\mathrm{rank}(\\mathbf{A})$ = the number of nonzero rows in $\\mathbf{B}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "colab_type": "text",
    "id": "zjazwL2vAOsD",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Consistency of** $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$\n",
    "\n",
    "  A linear system of equations $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$ is consistent if and only if $\\mathrm{rank}(\\mathbf{A})=\\mathrm{rank}(\\mathbf{A}|\\mathbf{b})$. \n",
    "\n",
    "  Suppose a linear system $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$ with $m$ equations and $n$ unknowns is consistent.\n",
    "  If $\\mathrm{rank}(\\mathbf{A})=r\\leq n$, then the solution of the system contains $n -r$ parameters. This means that we have the unique solution when $r=n$.\n",
    "\n",
    "  >${\\scriptsize\n",
    "  \\left(\\begin{array}{cccc|c}\n",
    "    a_{11} & a_{12} & \\cdots & a_{1n} & b_1\\\\ \n",
    "    a_{21} & a_{22} & \\ddots & a_{2n} & b_2\\\\ \n",
    "    \\vdots & \\ddots & \\ddots & \\vdots & \\vdots\\\\ \n",
    "    a_{m1} & a_{m2} & \\cdots & a_{mn} & b_m\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{cccc:ccc|c}\n",
    "    1      & a_{12}' & \\cdots & a_{1{\\color{red}r}}'& a_{1r+1}' & \\cdots   & a_{1n}' & b_1' \\\\ \n",
    "    0      & 1       & \\ddots & \\vdots & a_{2r+1}' & \\ddots   & a_{2n}' & b_2' \\\\\n",
    "    \\vdots & \\ddots  & \\ddots & \\vdots & \\vdots    & \\ddots   & \\vdots  & \\vdots \\\\    \n",
    "    0      & \\cdots  & 0      & 1      & a_{{\\color{red}r}r+1}' & \\cdots   & a_{rn}' & b_r' \\\\ \\hdashline     \n",
    "    0      & 0       & 0      & 0      & 0         & 0        & 0       & {\\color{red} 0} \\\\\n",
    "    \\vdots & \\vdots  & \\vdots & \\vdots & \\vdots    & \\vdots   & \\vdots  & {\\color{red} \\vdots} \\\\    \n",
    "    0      & 0       & 0      & 0      & 0         & 0        & 0       & {\\color{red} 0}    \n",
    "  \\end{array}\\right) }\n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  <img src=\"figures/ch08_figure02.png?\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "colab_type": "text",
    "id": "lzKg3R3KAOsD",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercises 8.3\n",
    "\n",
    "* 1, 3, 5, 9\n",
    "* 11, 13\n",
    "* 15, 16, 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Obp_SEjDAOsE",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.4 Determinants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2vRVtE0lAOsF",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Determinant of a $2 \\times 2$ Matrix**\n",
    "\n",
    ">$\\mathrm{det}(\\mathbf{A})=\n",
    "   \\begin{vmatrix}\n",
    "     a_{11} & a_{12}\\\\ \n",
    "     a_{21} & a_{22}\n",
    "   \\end{vmatrix}=a_{11}a_{22}-a_{12}a_{21}\n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lzVenxnLAOsG",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Determinant of a $3 \\times 3$ Matrix**\n",
    "\n",
    ">$\n",
    "   \\mathrm{det}(\\mathbf{A})=\n",
    "   \\begin{vmatrix}\n",
    "     a_{11} & a_{12} & a_{13}\\\\ \n",
    "     a_{21} & a_{22} & a_{23}\\\\\n",
    "     a_{31} & a_{32} & a_{33}\n",
    "   \\end{vmatrix}={\\scriptsize\n",
    "   a_{11}(-1)^{1+1} \n",
    "   \\begin{vmatrix}\n",
    "     a_{22} & a_{23}\\\\ \n",
    "     a_{32} & a_{33}\n",
    "   \\end{vmatrix} +\n",
    "   a_{12}(-1)^{1+2} \n",
    "   \\begin{vmatrix}\n",
    "     a_{21} & a_{23}\\\\ \n",
    "     a_{31} & a_{33}\n",
    "   \\end{vmatrix} +\n",
    "   a_{13}(-1)^{1+3} \n",
    "   \\begin{vmatrix}\n",
    "     a_{21} & a_{22}\\\\ \n",
    "     a_{31} & a_{32}\n",
    "   \\end{vmatrix}} \n",
    "  $   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-ReEQwTAOsG",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Cofactor and Minor**\n",
    "\n",
    "  The **cofactor of $a_{ij}$** is the determinant\n",
    "  \n",
    "  >$C_{ij}=(-1)^{i +j} M_{ij}$\n",
    "  \n",
    "  where $M_{ij}$ is the determinant of the submatrix obtained by deleting the $i$-th row \n",
    "  and the $j$-th column of $\\mathbf{A}$. The determinant $M_{ij}$ is called a **minor determinant** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kobviaIDAOsH",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Cofactor Expansion of a Determinant (Laplace Development)**\n",
    "\n",
    "  Let $\\mathbf{A}=\\left(a_{ij}\\right)_{n \\times n}$ be an $n \\times n$ matrix. For each $1 \\leq i \\leq n$, \n",
    "  **the cofactor expansion of $\\mathrm{det}(\\mathbf{A})$ along the $i$-th row** is\n",
    "  \n",
    "  >$\\displaystyle\n",
    "  \\mathrm{det}(\\mathbf{A})=\\sum_{k=1}^na_{ik}C_{ik}$\n",
    "  \n",
    "  For each $1 \\leq j \\leq n$, **the cofactor expansion of $\\mathrm{det}(\\mathbf{A})$ along the $j$-th column** is\n",
    "  \n",
    "  >$\\displaystyle\n",
    "  \\mathrm{det}(\\mathbf{A})=\\sum_{k=1}^na_{kj}C_{kj}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ktBzeTZZAOsI",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercises 8.4\n",
    "\n",
    "* 1, 11, 13, 21, 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q0tgTJogAOsI",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.5 Properties of Determinants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9B845k0KAOsJ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* If $\\mathbf{A}^T$ is the transpose of the $n \\times n$ matrix $\\mathbf{A}$, \n",
    "  then $\\mathrm{det}(\\mathbf{A}^T)=\\mathrm{det}(\\mathbf{A})$\n",
    "  \n",
    "* If any two rows (columns) of an $n \\times n$ matrix $\\mathbf{A}$ are the same, then $\\mathrm{det}(\\mathbf{A})=0$\n",
    "\n",
    "* If all the entries in a row (column) of an $n \\times n$ matrix $\\mathbf{A}$ are zero, then $\\mathrm{det}(\\mathbf{A})=0$\n",
    "\n",
    "* If $\\mathbf{B}$ is the matrix obtained by interchanging any two rows (columns) of an $n \\times n$ matrix $\\mathbf{A}$, then $\\mathrm{det}(\\mathbf{B})=-\\mathrm{det}(\\mathbf{A})$\n",
    "\n",
    "* If $\\mathbf{B}$ is the matrix obtained by multiplying a row (column) by a nonzero real number $k$,\n",
    "  then $\\mathrm{det}(\\mathbf{B})=k\\mathrm{det}(\\mathbf{A})$\n",
    "  \n",
    "* If $\\mathbf{A}$ and $\\mathbf{B}$ are both $n \\times n$ matrices, then \n",
    "  $\\mathrm{det}(\\mathbf{AB})=\\mathrm{det}(\\mathbf{A})\\cdot \\mathrm{det}(\\mathbf{B})$\n",
    "  \n",
    "* Suppose $\\mathbf{B}$ is the matrix obtained from an $n \\times n$ matrix $\\mathbf{A}$ by multiplying the entries\n",
    "  in a row (column) by a nonzero real number $k$ and adding the result to the corresponding entries in another\n",
    "  row (column). Then $\\mathrm{det}(\\mathbf{B})=\\mathrm{det}(\\mathbf{A})$\n",
    "  \n",
    "* If $\\mathbf{A}$ is an $n \\times n$ triangular matrix, then $\\mathrm{det}(\\mathbf{A})=a_{11} a_{22}\\cdots a_{nn}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tKsN2Dy-AOsK",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Alien Cofactors**\n",
    "\n",
    "Suppose $\\mathbf{A}$ is an $n \\times n$ matrix. If $a_{i1}, a_{i2}, \\cdots, a_{in}$ are the entries\n",
    "in the $i$-th row and $C_{p1}, C_{p2}, \\cdots, C_{pn}$ are the cofactors of the entries in the $p$-th row, then\n",
    "\n",
    ">$\\displaystyle\\sum_{k=1}^n a_{ik}C_{pk}=0\\;\\;\\text{for}\\; i \\neq p$\n",
    "\n",
    "If $a_{1j}, a_{2j}, \\cdots, a_{nj}$ are the entries\n",
    "in the $j$-th column and $C_{1p}, C_{2p}, \\cdots, C_{np}$ are the cofactors of the entries in the $p$-th column, then\n",
    "\n",
    ">$\\displaystyle\\sum_{k=1}^n a_{kj}C_{kp}=0\\;\\;\\text{for}\\; j \\neq p$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wjh8SE5nAOsK",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercises 8.5\n",
    "\n",
    "* 1, 3, 5, 11, 12, 16\n",
    "* 18, 20\n",
    "* 24, 25, 26, 28, 38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ig3cmwbLAOsL",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.6 Inverse of a Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* If $\\mathbf{A}$ is an $n \\times n$ matrix and there exists an $n \\times n$ matrix $\\mathbf{B}$ such that\n",
    "\n",
    "  >$\\mathbf{A}\\mathbf{B}=\\mathbf{B}\\mathbf{A}=\\mathbf{I}$,\n",
    "  \n",
    "  then $\\mathbf{A}$ is said to be **nonsingular** or **invertible** and $\\mathbf{B}$ \n",
    "  is the **inverse** of $\\mathbf{A}$\n",
    "\n",
    "* An $n \\times n$ matrix that has no inverse is called **singular**. If $\\mathbf{A}$ is nonsingular, \n",
    "  its inverse is denoted by $\\mathbf{B}=\\mathbf{A}^{-1}$\n",
    "  \n",
    "* **Properties of the Inverse**\n",
    "\n",
    "  Let $\\mathbf{A}$ and $\\mathbf{B}$ be nonsingular matrices. Then\n",
    "  \n",
    "  * $\\left(\\mathbf{A}^{-1}\\right)^{-1}=\\mathbf{A}$\n",
    "  \n",
    "  * $\\left(\\mathbf{A}\\mathbf{B}\\right)^{-1}=\\mathbf{B}^{-1}\\mathbf{A}^{-1}$\n",
    "  \n",
    "  * $\\left(\\mathbf{A}^T\\right)^{-1}=\\left(\\mathbf{A}^{-1}\\right)^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "colab_type": "text",
    "id": "YbBM3KKkAOsM",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Adjoint Matrix**\n",
    "\n",
    "  >$\\displaystyle\n",
    "   \\mathrm{adj}(\\mathbf{A})=\n",
    "   \\begin{pmatrix}\n",
    "     C_{11} & C_{12} & \\cdots & C_{1n}\\\\ \n",
    "     C_{21} & C_{22} & \\cdots & C_{2n}\\\\ \n",
    "     \\vdots &        &        & \\vdots\\\\ \n",
    "     C_{n1} & C_{n2} & \\cdots & C_{nn}\n",
    "   \\end{pmatrix}^T   \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Finding the Inverse**\n",
    "  \n",
    "  Let $\\mathbf{A}$ be an $n \\times n$ matrix. If $\\mathrm{det}(\\mathbf{A})\\neq 0$ (**nonsingular**), then\n",
    "  \n",
    "  >$\\displaystyle\n",
    "   \\mathbf{A}^{-1}=\\frac{\\mathrm{adj}(\\mathbf{A})}{\\mathrm{det}(\\mathbf{A})}\n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  or\n",
    "\n",
    "  > ![inverse](figures/ch08_figure03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JgDyrmrTAOsM",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Using the Inverse to Solve Systems**\n",
    "\n",
    "  The coefficient matrix $\\mathbf{A}$ is $n \\times n$. In particular, if $\\mathbf{A}$ is nonsingular,\n",
    "  the system $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$ can be solved by\n",
    "  \n",
    "  >$\\mathbf{x}=\\mathbf{A}^{-1}\\mathbf{b}$\n",
    "  \n",
    "  A homogeneous system of $n$ linear equations in $n$ unknowns $\\mathbf{A}\\mathbf{x}=\\mathbf{0}$ $~$has\n",
    "  \n",
    "  * only the trivial solution if and only if $\\mathbf{A}$ is nonsingular\n",
    "  \n",
    "  * a nontrivial solution if and only if $\\mathbf{A}$ is singular "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qDOUyUWgAOsN",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercises 8.6\n",
    "\n",
    "* 1, 11, 13\n",
    "* 19, 21, 30, 32\n",
    "* 33 - 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CXrA8VLoAOsQ",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 8.7 Cramer's Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AD97odiMAOsR",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If $\\mathrm{det}(\\mathbf{A}) \\neq 0$, the solution of the system is given by\n",
    "\n",
    "  > $\\displaystyle x_k=\\frac{\\mathrm{det}(\\mathbf{A}_k)}{\\mathrm{det}(\\mathbf{A})}$, $~$$k=1, 2, \\cdots, n$\n",
    "  \n",
    "where\n",
    "\n",
    "  >$\\mathbf{A}_k=\n",
    "  \\begin{pmatrix}\n",
    "    a_{11} & \\cdots & a_{1k-1} & b_1    & a_{1k+1} & \\cdots & a_{1n}\\\\ \n",
    "    a_{21} & \\cdots & a_{2k-1} & b_2    & a_{2k+1} & \\cdots & a_{2n} \\\\ \n",
    "    \\vdots &        & \\vdots   & \\vdots & \\vdots   &        & \\vdots\\\\ \n",
    "    a_{n1} & \\cdots & a_{nk-1} & b_n    & a_{nk+1} & \\cdots & a_{nn}\n",
    "  \\end{pmatrix}  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RgdFSUurAOsR",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercises 8.7\n",
    "\n",
    "* 1, 3, 5, 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W3amBwHFAOsS",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.8 The Eigenvalue Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Let $\\mathbf{A}$ be an $n \\times n$ matrix. A number $\\lambda$ is said to be an **eigenvalue** of \n",
    "  $\\mathbf{A}$ if there exists a nonzero solution vector $\\mathbf{k}$ of the linear system\n",
    "\n",
    "  >$\\mathbf{A}\\mathbf{k}=\\lambda\\mathbf{k}$\n",
    "\n",
    "  and the solution vector $\\mathbf{k}$ is said to be an **eigenvector** corresponding to the eigenvalue $\\lambda$\n",
    "  \n",
    "* The problem of solving $\\mathbf{A}\\mathbf{k}=\\lambda\\mathbf{k}$ for nonzero vectors $\\mathbf{k}$ is\n",
    "  called to be the **eigenvalue problem** for $\\mathbf{A}$\n",
    "  \n",
    "* We must solve the **characteristic equation** \n",
    "  $\\mathrm{det}(\\mathbf{A} -\\lambda\\mathbf{I})=0$ to find an eigenvalue $\\lambda$\n",
    "  \n",
    "* To find an eigenvector $\\mathbf{k}$ corresponding to an eigenvalue $\\lambda$, we solve \n",
    "  $(\\mathbf{A} -\\lambda\\mathbf{I})\\mathbf{k}=\\mathbf{0}$ by applying Gauss elimination \n",
    "  to $(\\mathbf{A} -\\lambda\\mathbf{I}|\\mathbf{0})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example:** $\\text{ }$ Find the eigenvalues and eigenvectors of\n",
    " \n",
    "  >$\\mathbf{A}=\n",
    "  \\left(\\begin{array}{rrr}\n",
    "    1 & 2 &  1\\\\ \n",
    "    6 &-1 &  0\\\\ \n",
    "   -1 &-2 & -1\n",
    "  \\end{array}\\right)   \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  To find the eigenvalues, we solve\n",
    "  \n",
    "  >${\\scriptsize\n",
    "  \\mathrm{det} (\\mathbf{A} -\\lambda\\mathbf{I}) =\n",
    "  \\begin{vmatrix}\n",
    "    1 -\\lambda & \\;\\;\\,2 & \\;\\;\\,1\\\\ \n",
    "    6 & -1 -\\lambda & \\;\\;\\,0\\\\ \n",
    "    -1\\;\\;\\, & -2 & -1 -\\lambda\n",
    "  \\end{vmatrix}=0}  \n",
    "  $\n",
    "  \n",
    "  It follows that the characteristic equation is $-\\lambda^3 -\\lambda^2 +12\\lambda=-\\lambda(\\lambda+4)(\\lambda-3)=0$\n",
    "  \n",
    "  Hence the eigenvalues are $\\lambda_1=-4$, $\\lambda_2=0$, $\\lambda_3=3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  For $\\lambda_1=-4$, we have\n",
    "  \n",
    "  >$\n",
    "  (\\mathbf{A} +4\\mathbf{I}|\\mathbf{0}) =\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    5 & 2 &  1 & 0\\\\ \n",
    "    6 & 3 &  0 & 0\\\\ \n",
    "   -1 &-2 &  3 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 0 & 1 & 0\\\\ \n",
    "    0 & 1 &-2 & 0\\\\ \\hdashline\n",
    "    0 & 0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Thus $k_1=-k_3$, $\\text{ }k_2=2k_3$. Choosing $\\text{ }k_3=1$ gives the eigenvector\n",
    "  \n",
    "  >$\\mathbf{k}_1=\n",
    "  \\left(\\begin{array}{r}\n",
    "    -1\\\\ \n",
    "     2\\\\ \n",
    "     1\n",
    "  \\end{array}\\right)  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  For $\\lambda_2=0$, $\\text{ }$we have\n",
    "  \n",
    "  >$\n",
    "  (\\mathbf{A} -0\\mathbf{I}|\\mathbf{0}) =\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 &  1 & 0\\\\ \n",
    "    6 &-1 &  0 & 0\\\\ \n",
    "   -1 &-2 & -1 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 0 & \\frac{1}{13} & 0\\\\ \n",
    "    0 & 1 & \\frac{6}{13} & 0\\\\ \\hdashline\n",
    "    0 & 0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Thus $k_1=-\\frac{1}{13}k_3$, $\\text{ }k_2=-\\frac{6}{13}k_3$. $\\text{ }$Choosing $\\text{ }k_3=1$ gives the eigenvector\n",
    "  \n",
    "  >$\\mathbf{k}_2=\n",
    "  \\left(\\begin{array}{r}\n",
    "    -\\frac{1}{13}\\\\ \n",
    "    -\\frac{6}{13}\\\\ \n",
    "    1\n",
    "  \\end{array}\\right)  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1WHm8niDAOsT",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  For $\\lambda_3=3$, $\\text{ }$we have\n",
    "  \n",
    "  >$\n",
    "  (\\mathbf{A} -3\\mathbf{I}|\\mathbf{0}) =\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "   -2 & 2 &  1 & 0\\\\ \n",
    "    6 &-4 &  0 & 0\\\\ \n",
    "   -1 &-2 & -4 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 0 & 1 & 0\\\\ \n",
    "    0 & 1 & \\frac{3}{2} & 0\\\\ \\hdashline\n",
    "    0 & 0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Thus $k_1=-k_3$, $\\text{ }k_2=-\\frac{3}{2}k_3$. $\\text{ }$Choosing $\\text{ }k_3=1$ gives the eigenvector\n",
    "  \n",
    "  >$\\mathbf{k}_3=\n",
    "  \\left(\\begin{array}{r}\n",
    "   -1\\\\ \n",
    "   -\\frac{3}{2}\\\\ \n",
    "    1\n",
    "  \\end{array}\\right)  \n",
    "  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hF_02tP1AOsT",
    "outputId": "a4adb1d5-e472-4d99-a8db-a41f02471ea7",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left( \\left[ \\left( -4, \\  1, \\  \\left[ \\left[\\begin{matrix}-1\\\\2\\\\1\\end{matrix}\\right]\\right]\\right), \\  \\left( 0, \\  1, \\  \\left[ \\left[\\begin{matrix}- \\frac{1}{13}\\\\- \\frac{6}{13}\\\\1\\end{matrix}\\right]\\right]\\right), \\  \\left( 3, \\  1, \\  \\left[ \\left[\\begin{matrix}-1\\\\- \\frac{3}{2}\\\\1\\end{matrix}\\right]\\right]\\right)\\right],\\right)$"
      ],
      "text/plain": [
       "⎛⎡⎛       ⎡⎡-1⎤⎤⎞  ⎛      ⎡⎡-1/13⎤⎤⎞  ⎛      ⎡⎡ -1 ⎤⎤⎞⎤ ⎞\n",
       "⎜⎢⎜       ⎢⎢  ⎥⎥⎟  ⎜      ⎢⎢     ⎥⎥⎟  ⎜      ⎢⎢    ⎥⎥⎟⎥ ⎟\n",
       "⎜⎢⎜-4, 1, ⎢⎢2 ⎥⎥⎟, ⎜0, 1, ⎢⎢-6/13⎥⎥⎟, ⎜3, 1, ⎢⎢-3/2⎥⎥⎟⎥,⎟\n",
       "⎜⎢⎜       ⎢⎢  ⎥⎥⎟  ⎜      ⎢⎢     ⎥⎥⎟  ⎜      ⎢⎢    ⎥⎥⎟⎥ ⎟\n",
       "⎝⎣⎝       ⎣⎣1 ⎦⎦⎠  ⎝      ⎣⎣  1  ⎦⎦⎠  ⎝      ⎣⎣ 1  ⎦⎦⎠⎦ ⎠"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy\n",
    "sympy.init_printing()\n",
    "\n",
    "A = sympy.Matrix([[1, 2, 1], [6, -1, 0], [-1, -2, -1]])\n",
    "A.eigenvects(),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example:** $\\text{ }$ Find the eigenvalues and eigenvectors of \n",
    "   >$\\mathbf{A}=\n",
    "   \\left(\\begin{array}{rr}\n",
    "     3 & 4 \\\\ \n",
    "    -1 & 7 \n",
    "   \\end{array}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "   From the characteristic equation\n",
    "   \n",
    "   >$\n",
    "   \\mathrm{det}(\\mathbf{A} -\\lambda\\mathbf{I})=\n",
    "   \\left|\\begin{array}{cc}\n",
    "     3-\\lambda & 4 \\\\ \n",
    "    -1 & 7 -\\lambda \n",
    "   \\end{array}\\right|\n",
    "   =(\\lambda -5)^2=0\n",
    "   $,\n",
    "   \n",
    "   we see $\\lambda_1=\\lambda_2=5$ is an eigenvalue of algebraic multiplicity 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  To find\n",
    "   the eigenvector(s) corresponding to $\\lambda_1=5$, $\\text{ }$we resort to \n",
    "   the system $(\\mathbf{A} -5\\mathbf{I}|\\mathbf{0})$\n",
    "   \n",
    "  >$\n",
    "  (\\mathbf{A} -5\\mathbf{I}|\\mathbf{0}) =\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "   -2 & 4 & 0\\\\ \n",
    "   -1 & 2 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "    1 &-2 & 0\\\\ \\hdashline\n",
    "    0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Thus $k_1=2k_2$. $\\text{ }$If we choose $k_2=1$, we find the single eigenvector \n",
    "  \n",
    "  >$\\mathbf{k}_1=\\begin{pmatrix}\n",
    "     2 \\\\ 1\n",
    "   \\end{pmatrix}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mLqzpeH6AOsX",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  We define the geometric multiplicity of an eigenvalue\n",
    "  to be the number of linearly independent eigenvectors for the eigenvalue.\n",
    "  When the geometric multiplicity of an eigenvalue is less than the algebraic \n",
    "  multiplicity, $\\text{ }$we say the matrix is *defective*. $\\text{ }$In the case of defective matrices,\n",
    "  we must search for additional system \n",
    "\n",
    "  >$\n",
    "  (\\mathbf{A} -5\\mathbf{I}|\\mathbf{k}_1) =\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "   -2 & 4 & 2\\\\ \n",
    "   -1 & 2 & 1\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "    1 &-2 & -1\\\\ \\hdashline\n",
    "    0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Thus $k_1-2k_2=-1$. $\\text{ }$If we choose $k_2=0$, we find the generalized eigenvector\n",
    "  \n",
    "  >$\\mathbf{k}_2=\\begin{pmatrix}\n",
    "     -1 \\\\ \\;\\;0\n",
    "   \\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3CdNxcPIAOsY",
    "outputId": "161aa32f-c1e8-484c-c3b6-22dcbff3a73e",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[ \\left( 5, \\  2, \\  \\left[ \\left[\\begin{matrix}2\\\\1\\end{matrix}\\right]\\right]\\right)\\right]$"
      ],
      "text/plain": [
       "⎡⎛      ⎡⎡2⎤⎤⎞⎤\n",
       "⎢⎜5, 2, ⎢⎢ ⎥⎥⎟⎥\n",
       "⎣⎝      ⎣⎣1⎦⎦⎠⎦"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = sympy.Matrix([[3, 4], [-1, 7]])\n",
    "A.eigenvects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example:** $\\text{ }$ Find the eigenvalues and eigenvectors of\n",
    " \n",
    "  >$\\mathbf{A}=\n",
    "  \\left(\\begin{array}{rrr}\n",
    "    9 & 1 & 1\\\\ \n",
    "    1 & 9 & 1\\\\ \n",
    "    1 & 1 & 9\n",
    "  \\end{array}\\right)   \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  The characteristic equation\n",
    "  \n",
    "  >$\n",
    "  \\mathrm{det} (\\mathbf{A} -\\lambda\\mathbf{I}) =\n",
    "  \\begin{vmatrix}\n",
    "    9 -\\lambda & 1 & 1\\\\ \n",
    "    1 & 9 -\\lambda & 1\\\\ \n",
    "    1 & 1 & 9 -\\lambda\n",
    "  \\end{vmatrix}=-(\\lambda-11)(\\lambda-8)^2=0  \n",
    "  $\n",
    "  \n",
    "  shows that $\\lambda_1=11$ and that $\\lambda_2=\\lambda_3=8$ is an eigenvalue of multiplicity 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  For $\\lambda_1=11$, we have\n",
    "  \n",
    "  >$\n",
    "  (\\mathbf{A} -11\\mathbf{I}|\\mathbf{0}) =\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "   -2 & 1 &  1 & 0\\\\ \n",
    "    1 &-2 &  1 & 0\\\\ \n",
    "    1 & 1 & -2 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 0 & -1 & 0\\\\ \n",
    "    0 & 1 & -1 & 0\\\\ \\hdashline\n",
    "    0 & 0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Thus $k_1=k_3$, $k_2=k_3$. Choosing $k_3=1$ gives the eigenvector\n",
    "  \n",
    "  >$\\mathbf{k}_1=\n",
    "  \\left(\\begin{array}{r}\n",
    "    1\\\\ \n",
    "    1\\\\ \n",
    "    1\n",
    "  \\end{array}\\right)  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  For $\\lambda_2=8$, we have\n",
    "  \n",
    "  >$\n",
    "  (\\mathbf{A} -8\\mathbf{I}|\\mathbf{0}) =\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 1 &  1 & 0\\\\ \n",
    "    1 & 1 &  1 & 0\\\\ \n",
    "    1 & 1 &  1 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 1 & 1 & 0\\\\ \\hdashline\n",
    "    0 & 0 & 0 & 0\\\\ \n",
    "    0 & 0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Here $k_1 +k_2 +k_3=0$, we are free to select two of the variables arbitrarily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z-PBMpKLAOsc",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "  Choosing, on the one hand, $k_2=1$, $k_3=0$, and on the other, $k_2=0$, $k_3=1$, we obtain\n",
    "  two linearly independent eigenvectors\n",
    "  \n",
    "  >$\\mathbf{k}_2=\n",
    "  \\left(\\begin{array}{r}\n",
    "   -1\\\\ \n",
    "    1\\\\ \n",
    "    0\n",
    "  \\end{array}\\right) \\text{ and } \n",
    "  \\mathbf{k}_3=\n",
    "  \\left(\\begin{array}{r}\n",
    "   -1\\\\ \n",
    "    0\\\\ \n",
    "    1\n",
    "  \\end{array}\\right)\n",
    "  $\n",
    "  \n",
    "  corresponding to a single eigenvalue. If instead we choose $k_2=1$, $k_3=1$ and then $k_2=1$, $k_3=-1$, we obtain,\n",
    "  respectively, two entirely different but orthogonal eigenvectors\n",
    "  \n",
    "  >$\\mathbf{k}_2=\n",
    "  \\left(\\begin{array}{r}\n",
    "   -2\\\\ \n",
    "    1\\\\ \n",
    "    1\n",
    "  \\end{array}\\right) \\text{ and } \n",
    "  \\mathbf{k}_3=\n",
    "  \\left(\\begin{array}{r}\n",
    "    0\\\\ \n",
    "    1\\\\ \n",
    "   -1\n",
    "  \\end{array}\\right)\n",
    "  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RvUzJZggAOsd",
    "outputId": "dba4b1c2-c869-4bb8-a984-375b81d9a4df",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[ \\left( 8, \\  2, \\  \\left[ \\left[\\begin{matrix}-1\\\\1\\\\0\\end{matrix}\\right], \\  \\left[\\begin{matrix}-1\\\\0\\\\1\\end{matrix}\\right]\\right]\\right), \\  \\left( 11, \\  1, \\  \\left[ \\left[\\begin{matrix}1\\\\1\\\\1\\end{matrix}\\right]\\right]\\right)\\right]$"
      ],
      "text/plain": [
       "⎡⎛      ⎡⎡-1⎤  ⎡-1⎤⎤⎞  ⎛       ⎡⎡1⎤⎤⎞⎤\n",
       "⎢⎜      ⎢⎢  ⎥  ⎢  ⎥⎥⎟  ⎜       ⎢⎢ ⎥⎥⎟⎥\n",
       "⎢⎜8, 2, ⎢⎢1 ⎥, ⎢0 ⎥⎥⎟, ⎜11, 1, ⎢⎢1⎥⎥⎟⎥\n",
       "⎢⎜      ⎢⎢  ⎥  ⎢  ⎥⎥⎟  ⎜       ⎢⎢ ⎥⎥⎟⎥\n",
       "⎣⎝      ⎣⎣0 ⎦  ⎣1 ⎦⎦⎠  ⎝       ⎣⎣1⎦⎦⎠⎦"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = sympy.Matrix([[9, 1, 1], [1, 9, 1], [1, 1, 9]])\n",
    "A.eigenvects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TNaLuae8AOsh",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Let $\\mathbf{A}$ be a square matrix with real entries. If $\\lambda=\\alpha +i\\beta$, $\\beta \\neq 0$,\n",
    "  is a complex eigenvalue of $\\mathbf{A}$,\n",
    "  \n",
    "  >$\\mathbf{A}\\mathbf{\\bar{k}}=\\bar{\\lambda}\\mathbf{\\bar{k}}$\n",
    "  \n",
    "* $\\lambda=0$ is an eigenvalue of $\\mathbf{A}$ if and only if $\\mathbf{A}$ is singular\n",
    "\n",
    "* If $\\lambda$ is an eigenvalue of nonsingular $\\mathbf{A}$ with eigenvector $\\mathbf{k}$,\n",
    "  $1/\\lambda$ is an eigenvalue of $\\mathbf{A}^{-1}$ with the same eigenvector $\\mathbf{k}$\n",
    "  \n",
    "* The eigenvalues of an upper triangular, lower triangular, and diagonal matrix are the main diagonal entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FxmN7VbPAOsi",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercises 8.8\n",
    "\n",
    "* 1, 3, 7, 13, 19\n",
    "* 23, 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dmzDgpKjAOsk",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.9 Powers of Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qg4_a_fzAOsl",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Cayley-Hamilton Theorem**\n",
    "\n",
    "  If $(-1)^n \\lambda^n +c_{n-1}\\lambda^{n-1} + \\cdots +c_1 \\lambda +c_0 = 0$ is the characteristic equation\n",
    "  of $n \\times n$ matrix $\\mathbf{A}$, then\n",
    "  \n",
    "  $$(-1)^n \\mathbf{A}^n +c_{n-1}\\mathbf{A}^{n-1} + \\cdots +c_1 \\mathbf{A} +c_0 \\mathbf{I} = \\mathbf{0}$$\n",
    "  \n",
    "  And we can write\n",
    "  \n",
    "  $$\\mathbf{A}^m = a_0 \\mathbf{I} +a_1 \\mathbf{A} +\\cdots +a_{n-1}\\mathbf{A}^{n-1}$$\n",
    "    \n",
    "  and the equation for the eigenvalues\n",
    "    \n",
    "  $$\\lambda^m = a_0 +a_1 \\lambda +\\cdots +a_{n-1}\\lambda^{n-1}$$\n",
    "    \n",
    "  hold for the same constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HGtFWkTwAOsn",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercises 8.9\n",
    "\n",
    "* 1, 3, 5, 7\n",
    "* 11, 12, 13, 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GuaRCgkAOsn",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 8.10 Orthogonal Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QtUyfBt3AOso",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Let $\\mathbf{A}$ be a *symmetric* matrix ($\\mathbf{A}=\\mathbf{A}^T$) with *real* entries. Then the eigenvalues of $\\mathbf{A}$ are *real*\n",
    "\n",
    "* Let $\\mathbf{A}$ be a *symmetric* matrix. Then eigenvectors corresponding to distinct(different) eigenvalues are *orthogonal*\n",
    "\n",
    "* An $n \\times n$ matrix $\\mathbf{A}$ is *orthogonal* ($\\mathbf{A}^{-1}=\\mathbf{A}^T$) if and only if its columns $\\mathbf{x}_1$, $\\mathbf{x}_2$, $\\cdots$, $\\mathbf{x}_n$ form an orthonormal set\n",
    "  \n",
    "  >$\\mathbf{x}_i \\cdot \\mathbf{x}_j=0$, $i \\neq j\\text{ }$ and $\\text{ }\\mathbf{x}_i \\cdot \\mathbf{x}_i=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MiQD3oV_AOsp",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "---\n",
    "\n",
    "* It may not be possible to find $n$ linearly independent eigenvectors for an $n \\times n$ matrix $\\mathbf{A}$\n",
    "  when some of eigenvalues are repeated (defective matrix). \n",
    "  \n",
    "* But a symmetric matrix is an exception. It can be proved that a set of \n",
    "  $n$ linearly independent eigenvectors can always be found for an $n \\times n$ symmetric matrix $\\mathbf{A}$ even\n",
    "  there is some repetition of the eigenvalues\n",
    "  \n",
    "* However, this does not mean that all eigenvectors are mutually orthogonal for an $n \\times n$ symmetric matrix $\\mathbf{A}$.\n",
    "  The set of eigenvectors corresponding to distinct eigenvalues are orthogonal; but different eigenvectors corresponding to \n",
    "  a repeated eigenvalue may not be orthogonal\n",
    "  \n",
    "* But it is always possible to *find* or *construct* a set of $n$ mutually orthogonal eigenvectors by using Gram-Schmidt orthogonalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f4TbvYHHAOsp",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example:** $\\text{ }$ Construct an orthogonal matrix from the eigenvectors of\n",
    "\n",
    "> $\n",
    "  \\mathbf{A}=\n",
    "  \\left(\\begin{array}{rrr}\n",
    "    7 & 4 & -4\\\\ \n",
    "    4 &-8 & -1\\\\ \n",
    "   -4 &-1 & -8\n",
    "  \\end{array}\\right)   \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WrEmN07pAOsq",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercises 8.10\n",
    "\n",
    "* 1, 3, 5, 7\n",
    "* 11, 13, 21\n",
    "* 25 - 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TiCMylHAOsr",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.11 Approximation of Eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WSL4LajSAOsr",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Let $\\lambda_1$, $\\lambda_2$, $\\cdots$, $\\lambda_k$, $\\cdots$, $\\lambda_n$ denote the eigenvalues of an $n \\times n$ matrix $\\mathbf{A}$. The eigenvalue $\\lambda_k$ is said to be the **dominant eigenvalue** of $\\mathbf{A}$ if $|\\lambda_k| > |\\lambda_i|$, $i=1,2,\\cdots,n$, but $\\text{ }i \\neq k$\n",
    "\n",
    "* An eigenvector corresponding to $\\lambda_k$ is called the **dominant eigenvector** of $\\mathbf{A}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Power Method**\n",
    "\n",
    "  Let us assume that the eigenvalues of $\\mathbf{A}$ are such that\n",
    "  $|\\lambda_1| > |\\lambda_2| \\geq |\\lambda_3| \\geq \\cdots \\geq |\\lambda_n|$\n",
    "  \n",
    "  and that the corresponding $n$ eigenvectors $\\mathbf{k}_1$, $\\mathbf{k}_2$, $\\cdots$, $\\mathbf{k}_n$\n",
    "  are linearly independent. Because of this last assumption, $n$ eigenvectors\n",
    "  can serve as a basis for $\\mathbb{R}^n$. For any nonzero $n \\times 1$ vector $\\mathbf{x}_0$, \n",
    "  \n",
    "  > $\\mathbf{x}_0 =c_1 \\mathbf{k}_1 +c_2 \\mathbf{k}_2 +c_3 \\mathbf{k}_3 +\\cdots +c_n \\mathbf{k}_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pb8NRJFuAOss",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  We shall also assume $\\mathbf{x}_0$ is chosen so that $c_1 \\neq 0$. $\\text{ }$We do the following procedure\n",
    "  \n",
    "  >${\\scriptsize\n",
    "  \\begin{align*}\n",
    "     \\mathbf{A}\\mathbf{x}_0 &= c_1 \\mathbf{A}\\mathbf{k}_1 +c_2 \\mathbf{A}\\mathbf{k}_2 \n",
    "         +c_3 \\mathbf{A}\\mathbf{k}_3 +\\cdots +c_n \\mathbf{A}\\mathbf{k}_n\\\\ \n",
    "     &\\;\\big\\Downarrow \\;\\;\\mathbf{x}_i=\\mathbf{A}\\mathbf{x}_{i -1}, \\;\\mathbf{A}\\mathbf{k}_j=\\lambda_j \\mathbf{k}_j\\\\ \n",
    "     \\mathbf{x}_1 &= c_1 \\lambda_1\\mathbf{k}_1 +c_2 \\lambda_2\\mathbf{k}_2 \n",
    "         +c_3 \\lambda_3\\mathbf{k}_3 +\\cdots +c_n \\lambda_n\\mathbf{k}_n\\\\ \n",
    "     &\\Downarrow \\\\\n",
    "     \\mathbf{A}\\mathbf{x}_1 &= c_1 \\lambda_1\\mathbf{A}\\mathbf{k}_1 +c_2 \\lambda_2\\mathbf{A}\\mathbf{k}_2 \n",
    "         +c_3 \\lambda_3\\mathbf{A}\\mathbf{k}_3 +\\cdots +c_n \\lambda_n\\mathbf{A}\\mathbf{k}_n\\\\ \n",
    "     &\\Downarrow \\\\\n",
    "     \\mathbf{x}_2 &= c_1 \\lambda_1^2\\mathbf{k}_1 +c_2 \\lambda_2^2\\mathbf{k}_2 \n",
    "         +c_3 \\lambda_3^2\\mathbf{k}_3 +\\cdots +c_n \\lambda_n^2\\mathbf{k}_n\\\\\n",
    "     &\\Downarrow \\\\\n",
    "     \\mathbf{x}_m &= c_1 \\lambda_1^m\\mathbf{k}_1 +c_2 \\lambda_2^m\\mathbf{k}_2 \n",
    "         +c_3 \\lambda_3^m\\mathbf{k}_3 +\\cdots +c_n \\lambda_n^m\\mathbf{k}_n\\\\ \n",
    "     &= \\lambda_1^m \\left[c_1 \\mathbf{k}_1 +c_2 \\left(\\frac{\\lambda_2}{\\lambda_1}\\right)^m\\mathbf{k}_2 \n",
    "         +c_3 \\left(\\frac{\\lambda_3}{\\lambda_1}\\right)^m\\mathbf{k}_3 +\\cdots +c_n \\left(\\frac{\\lambda_n}{\\lambda_1}\\right)^m\\mathbf{k}_n \\right]\\\\        &\\;\\big\\Downarrow \\;\\;m \\rightarrow \\infty\\\\\n",
    "     \\mathbf{x}_m &\\simeq \\lambda_1^m c_1 \\mathbf{k}_1   \n",
    "  \\end{align*} } \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  Since a nonzero constant multiple of an eigenvalue is an eigenvector, for large values of $m$ and under all the assumptions\n",
    "  that were made, the $n \\times 1$ vector $\\mathbf{x}_m$ is an approximation to a dominant eigenvector associated with\n",
    "  the dominant eigenvalue $\\lambda_1$\n",
    "  \n",
    "  If $\\mathbf{x}_m$ is an approximation to a dominant eigenvector, then the dominant eigenvalue $\\lambda_1$ can be approximated by\n",
    "  the **Rayleigh quotient**\n",
    "  \n",
    "  >$\\displaystyle\n",
    "   \\lambda_1=\\frac{\\mathbf{A}\\mathbf{x}_m \\cdot \\mathbf{x}_m}{\\mathbf{x}_m \\cdot \\mathbf{x}_m}\n",
    "  $\n",
    "  \n",
    "  Iteration often results in vectors whose entries become very large. Large numbers can cause a problem in computation. One way around\n",
    "  this difficulty is to use a **scaled-down** normalized vector\n",
    "  \n",
    "  >$\\displaystyle\n",
    "  \\mathbf{x}_m \\leftarrow \n",
    "    \\frac{\\mathbf{x}_m}{\\left \\| \\mathbf{x}_m \\right \\|}\n",
    "  $\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/SeoulTechPSE/EngMath/blob/master/codes/ch08_code1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxEEWQVvAOsu",
    "outputId": "e7d9a332-2844-441a-c9c1-4b8925c93828",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      "array([[ 4,  2],\n",
      "       [ 3, -1]])\n",
      "\n",
      "Dominant Eigenvector: [0.894 0.447]\n",
      "Dominant Eigenvalue: 5.0\n"
     ]
    }
   ],
   "source": [
    "%run ./codes/ch08_code1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PDnIIIxKAOsz",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Method of Deflation**\n",
    "\n",
    "  After we have found the dominant eigenvalue $\\lambda_1$ of a matrix $\\mathbf{A}$, it may still be necessary to find\n",
    "  nondominant eigenvalues. We will limit the discussion to the case where $\\mathbf{A}$ is a *symmetric* matrix.\n",
    "  \n",
    "  Suppose $\\lambda_1$ and $\\mathbf{k}_1$ are, respectively, the dominant eigenvalue and a corresponding *normalized* eigenvector of\n",
    "  a symmetric matrix $\\mathbf{A}$. Furthermore, suppose the eigenvalues of $\\mathbf{A}$ are such that\n",
    "  \n",
    "  > $|\\lambda_1| > |\\lambda_2| > |\\lambda_3| > \\cdots > |\\lambda_n|$\n",
    "  \n",
    "  In this case, the matrix\n",
    "  \n",
    "  > $\\mathbf{A}_1 =\\mathbf{A} -\\lambda_1\\mathbf{k}_1\\mathbf{k}_1^T$\n",
    "  \n",
    "  has eigenvalues $0$, $|\\lambda_2|$, $|\\lambda_3|$, $\\cdots$, $|\\lambda_n|$ and that eigenvectors of $\\mathbf{A}_1$ are also eigenvectors \n",
    "  of $\\mathbf{A}$. Note that $\\lambda_2$ is now the dominant eigenvalue of $\\mathbf{A}_1$.\n",
    " \n",
    " \n",
    "<a href=\"https://colab.research.google.com/github/SeoulTechPSE/EngMath/blob/master/codes/ch08_code2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dSI9WSMsAOsz",
    "outputId": "81386a4d-acd6-4336-efd2-1fb0b4b66273",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      "array([[ 1,  2, -1],\n",
      "       [ 2,  1,  1],\n",
      "       [-1,  1,  0]])\n",
      "\n",
      "k_1 = [0.707 0.707 0.   ]\n",
      "k_2 = [ 0.578 -0.577  0.577]\n",
      "k_3 = [-0.408  0.408  0.816]\n",
      "\n",
      "lambda_1 = 3.0\n",
      "lambda_2 = -2.0\n",
      "lambda_3 = 1.0\n"
     ]
    }
   ],
   "source": [
    "%run ./codes/ch08_code2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uIV5IV--AOs2",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Inverse Power Method**\n",
    "\n",
    "  If we want to find the smallest eigenvalue instead of the largest one, then we perform power\n",
    "  iteration for $\\mathbf{A}^{−1}$ (since the eigenvalues of $\\mathbf{A}^{-1}$ are the reciprocals of the eigenvalues of\n",
    "  $\\mathbf{A}$). Of course, we do not want to compute $\\mathbf{A}^{-1}$\n",
    "\n",
    " \n",
    "<a href=\"https://colab.research.google.com/github/SeoulTechPSE/EngMath/blob/master/codes/ch08_code3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FObTb70qAOs3",
    "outputId": "9318ad33-0e45-4ff0-aa9e-ebc062c5f481",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      "array([[ 4,  2],\n",
      "       [ 3, -1]])\n",
      "\n",
      "Eigenvector = [-0.316  0.949]\n",
      "Eigenvalue of Least Magnitude = -2.0\n"
     ]
    }
   ],
   "source": [
    "%run ./codes/ch08_code3.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FeFV03okAOs6",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercises 8.11\n",
    "\n",
    "* 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EoMSrGZ-AOs6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.12 Diagonalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kwnLMJNZAOs7",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For an $n \\times n$ matrix $\\mathbf{A}$, can we find an $n \\times n$ nonsingular matrix $\\mathbf{P}$ such that \n",
    "$\\mathbf{P}^{-1}\\mathbf{A}\\mathbf{P}=\\mathbf{D}$ is a diagonal matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cu3gprU9AOs8",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* An $n \\times n$ matrix $\\mathbf{A}$ is diagonalizable if and only if $\\mathbf{A}$ has $n$ linearly independent eigenvectors\n",
    "\n",
    "  Let $\\mathbf{k}_1$, $\\mathbf{k}_2$, $\\cdots$, $\\mathbf{k}_n$ be linearly independent eigenvectors corresponding to \n",
    "  eigenvalues $\\lambda_1$, $\\lambda_2$, $\\cdots$, $\\lambda_n$. Next form the matrix $\\mathbf{P}$ with column vectors\n",
    "  $\\mathbf{k}_1$, $\\mathbf{k}_2$, $\\cdots$, $\\mathbf{k}_n$\n",
    "  \n",
    "  >$\n",
    "  \\mathbf{P}= \\begin{pmatrix}\n",
    "    \\mathbf{k}_1 & \\mathbf{k}_2 & \\cdots & \\mathbf{k}_n\n",
    "  \\end{pmatrix}\n",
    "  $\n",
    "  \n",
    "  We can wrtie the product $\\mathbf{A}\\mathbf{P}$ as\n",
    "  \n",
    "  >$\n",
    "  \\begin{align*}\n",
    "   \\mathbf{A}\\mathbf{P}\n",
    "      &= \n",
    "      \\begin{pmatrix}\n",
    "        \\mathbf{A}\\mathbf{k}_1 & \\mathbf{A}\\mathbf{k}_2 & \\cdots & \\mathbf{A}\\mathbf{k}_n \n",
    "      \\end{pmatrix} =\n",
    "      \\begin{pmatrix}\n",
    "        \\lambda_1\\mathbf{k}_1 & \\lambda_2\\mathbf{k}_2 & \\cdots & \\lambda_n\\mathbf{k}_n \n",
    "      \\end{pmatrix} \\\\\n",
    "      &=\\begin{pmatrix}\n",
    "           \\mathbf{k}_1 & \\mathbf{k}_2 & \\cdots & \\mathbf{k}_n\n",
    "        \\end{pmatrix}\n",
    "        \\begin{pmatrix}\n",
    "           \\lambda_1 &  &  & \\\\ \n",
    "                     & \\lambda_2 &  & \\\\ \n",
    "                     &  & \\ddots & \\\\ \n",
    "                     &  &  & \\lambda_n\n",
    "        \\end{pmatrix}=\\mathbf{P}\\mathbf{D}\n",
    "  \\end{align*}  \n",
    "  $\n",
    "  \n",
    "  Multiplying the last equation on the left by $\\mathbf{P}^{-1}$ then gives $\\mathbf{P}^{-1}\\mathbf{A}\\mathbf{P}=\\mathbf{D}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "><img src=\"figures/ch08_figure04.png\" width=\"500\">\n",
    "\n",
    "* If an $n \\times n$ matrix $\\mathbf{A}$ has $n$ distinct eigenvalues, it is diagonalizable\n",
    "* An $n \\times n$ matrix $\\mathbf{A}$ can be *orthogonally* diagonalized if and only if $\\mathbf{A}$ is symmetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example:** $\\text{ }$ Diagonalize\n",
    "\n",
    "  >$\\mathbf{A}=\n",
    "  \\left(\\begin{array}{rrr}\n",
    "    9 & 1 & 1\\\\ \n",
    "    1 & 9 & 1\\\\ \n",
    "    1 & 1 & 9\n",
    "  \\end{array}\\right)\n",
    "  $\n",
    "  \n",
    "  The eigenvalues and corresponding orthogonal eigenvectors are\n",
    "  \n",
    "  >$\\lambda_1=11$, $\\lambda_2=\\lambda_3=8$\n",
    "  \n",
    "  >$\\mathbf{k}_1=\n",
    "  \\left(\\begin{array}{r}\n",
    "    1\\\\ \n",
    "    1\\\\ \n",
    "    1\n",
    "  \\end{array}\\right),  \n",
    "  \\mathbf{k}_2=\n",
    "  \\left(\\begin{array}{r}\n",
    "   -2\\\\ \n",
    "    1\\\\ \n",
    "    1\n",
    "  \\end{array}\\right) \\text{ and } \n",
    "  \\mathbf{k}_3=\n",
    "  \\left(\\begin{array}{r}\n",
    "    0\\\\ \n",
    "    1\\\\ \n",
    "   -1\n",
    "  \\end{array}\\right)\n",
    "  $  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  Multiplying these vectors, in turn, by the reciprocals of the norms $\\left \\| \\mathbf{k}_1 \\right \\|=\\sqrt{3}$,\n",
    "  $\\text{ }\\left \\| \\mathbf{k}_2 \\right \\|=\\sqrt{6}\\text{ }$ and $\\text{ }\\left \\| \\mathbf{k}_3 \\right \\|=\\sqrt{2}$,\n",
    "  we obtain an orthonormal set\n",
    "  \n",
    "  >$\n",
    "  \\mathbf{k}_1=\n",
    "  \\left(\\begin{array}{r}\n",
    "    \\frac{1}{\\sqrt{3}}\\\\ \n",
    "    \\frac{1}{\\sqrt{3}}\\\\ \n",
    "    \\frac{1}{\\sqrt{3}}\n",
    "  \\end{array}\\right),  \n",
    "  \\mathbf{k}_2=\n",
    "  \\left(\\begin{array}{r}\n",
    "    -\\frac{2}{\\sqrt{6}}\\\\ \n",
    "     \\frac{1}{\\sqrt{6}}\\\\ \n",
    "     \\frac{1}{\\sqrt{6}}\n",
    "  \\end{array}\\right) \\text{ and } \n",
    "  \\mathbf{k}_3=\n",
    "  \\left(\\begin{array}{r}\n",
    "    0\\;\\\\ \n",
    "    \\frac{1}{\\sqrt{2}}\\\\ \n",
    "   -\\frac{1}{\\sqrt{2}}\n",
    "  \\end{array}\\right)\n",
    "  $\n",
    "  \n",
    "  We then use these vectors as columns to construct an orthogonal matrix that diagonalizes $\\mathbf{A}$\n",
    "  \n",
    "  >$\\mathbf{P}=\n",
    "  \\left(\\begin{array}{rrr}\n",
    "    \\frac{1}{\\sqrt{3}} & -\\frac{2}{\\sqrt{6}} &  0\\;\\\\ \n",
    "    \\frac{1}{\\sqrt{3}} &  \\frac{1}{\\sqrt{6}} &  \\frac{1}{\\sqrt{2}}\\\\ \n",
    "    \\frac{1}{\\sqrt{3}} &  \\frac{1}{\\sqrt{6}} & -\\frac{1}{\\sqrt{2}}\n",
    "  \\end{array}\\right)  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-J-8RMmAOs9",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  This transforms $\\mathbf{A}$ to $\\mathbf{D}$\n",
    "  \n",
    "  >$\\mathbf{P}^{-1}\\mathbf{A}\\mathbf{P}=\\mathbf{P}^{T}\\mathbf{A}\\mathbf{P}=\n",
    "   \\begin{pmatrix}\n",
    "    11 & 0 & 0\\\\ \n",
    "     0 & 8 & 0\\\\ \n",
    "     0 & 0 & 8\n",
    "   \\end{pmatrix}=\\mathbf{D}$\n",
    "   \n",
    "   The entries in $\\mathbf{D}$ are the eigenvalues of $\\mathbf{A}$ and the order in which these numbers \n",
    "   appear on the diagonal corresponds to the order in which the eigenvectors are used as columns \n",
    "   in the matrix $\\mathbf{P}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example - Quadratic Forms:** $\\text{ }$ Identify the conic section whose equation $2x^2 +4xy -y^2 =1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " We can write the given equation as\n",
    "  \n",
    "  >$\n",
    "  \\begin{pmatrix}\n",
    "    x & y\n",
    "  \\end{pmatrix}\n",
    "  \\left(\\begin{array}{rr}\n",
    "    2 & 2\\\\ \n",
    "    2 &-1 \n",
    "  \\end{array}\\right)\n",
    "  \\begin{pmatrix}\n",
    "    x \\\\ \n",
    "    y\n",
    "  \\end{pmatrix}\n",
    "  =1 \\;\\text{ or }\\; \\mathbf{x}^T\\mathbf{A}\\mathbf{x}=1\n",
    "  $\n",
    "  \n",
    "  The eigenvalues and corresponding eigenvectors of $\\mathbf{A}$ are found to be\n",
    "  \n",
    "  >$\\lambda_1=-2$, $\\text{ }\\lambda_2=3$, $\\text{ }\\mathbf{k}_1=\\left(\\begin{array}{r} 1\\\\ -2 \\end{array}\\right)$,\n",
    "  >$\\text{ }\\mathbf{k}_2=\\left(\\begin{array}{r} 2\\\\ 1 \\end{array}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  Observe that $\\mathbf{k}_1$ and $\\mathbf{k}_2$ are orthogonal. $\\text{ }$Moreover, \n",
    "  $\\text{ }\\left \\| \\mathbf{k}_1 \\right \\| =\\left \\| \\mathbf{k}_2 \\right \\| =\\sqrt{5}$, and so the vectors\n",
    "  \n",
    "  >$\\mathbf{k}_1=\\left(\\begin{array}{r} \\frac{1}{\\sqrt{5}}\\\\ -\\frac{2}{\\sqrt{5}} \\end{array}\\right)\\text{ }$ and\n",
    "  >$\\text{ }\\mathbf{k}_2=\\left(\\begin{array}{r} \\frac{2}{\\sqrt{5}}\\\\ \\frac{1}{\\sqrt{5}} \\end{array}\\right)$\n",
    "  \n",
    "  are orthogonal. Hence, the matrix\n",
    "  \n",
    "  >$\\mathbf{P}=\n",
    "     \\left(\\begin{array}{rr} \\frac{1}{\\sqrt{5}} & \\frac{2}{\\sqrt{5}}\\\\ \n",
    "    -\\frac{2}{\\sqrt{5}} & \\frac{1}{\\sqrt{5}}\n",
    "    \\end{array}\\right)\n",
    "  $\n",
    "  \n",
    "  is orthogonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y5Ee39geAOs9",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " If we define the change of variables $\\text{ }\\mathbf{x}=\\mathbf{P}\\mathbf{\\hat{x}}\\text{ }$ \n",
    "  where $\\mathbf{\\hat{x}}=\\begin{pmatrix} \\hat{x} \\\\ \\hat{y} \\end{pmatrix}$, then the quadratic form can\n",
    "  be written\n",
    "  \n",
    "  >$\\mathbf{x}^T\\mathbf{A}\\mathbf{x}=\n",
    "   \\mathbf{\\hat{x}}^T\\mathbf{P}^T\\mathbf{A}\\mathbf{P}\\mathbf{\\hat{x}}\n",
    "   =\\mathbf{\\hat{x}}^T\\mathbf{D}\\mathbf{\\hat{x}}=\n",
    "   \\begin{pmatrix}\n",
    "     \\hat{x} & \\hat{y}\n",
    "   \\end{pmatrix}\n",
    "   \\left(\\begin{array}{rr}\n",
    "    -2 & 0\\\\ \n",
    "     0 & 3 \n",
    "   \\end{array}\\right)\n",
    "   \\begin{pmatrix}\n",
    "     \\hat{x} \\\\ \n",
    "     \\hat{y}\n",
    "   \\end{pmatrix}=1\\;\\;\\text{or}\\;\\; -2\\hat{x}^2 +3\\hat{y}^2 =1$\n",
    "  \n",
    "  This last equation is recognized as the standard form of a hyperbola\n",
    "  \n",
    "> <img src=\"figures/ch08_figure05.png?raw=1\" width=\"350\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zvC2gLNxAOs-",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercises 8.12\n",
    "\n",
    "* 7, 11, 13\n",
    "* 21, 23, 25\n",
    "* 31, 33, 37, 39\n",
    "* 41, 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h4PwNhKbAOs_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.13 LU Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "STpqZUlUAOtA",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Let $\\mathbf{A}$ be a square matrix. An *LU factorization* refers to the factorization of $\\mathbf{A}$ into \n",
    "  two factors – a lower triangular matrix $\\mathbf{L}$ and an upper triangular matrix $\\mathbf{U}$:\n",
    "\n",
    "  >$\\mathbf{A}=\\mathbf{L}\\mathbf{U}$\n",
    "  \n",
    "* Without a proper ordering or permutations in the matrix, the factorization may fail to materialize. \n",
    "  This is a procedural problem. It can be removed by simply reordering the rows of $\\mathbf{A}$.\n",
    "  It turns out that a proper permutation in rows (or columns) is sufficient for LU factorization. \n",
    "  LU factorization with partial pivoting (LUP) refers often to LU factorization with row permutations only\n",
    "  \n",
    "  >$\\mathbf{P}\\mathbf{A}=\\mathbf{L}\\mathbf{U}$\n",
    "  \n",
    "  where $\\mathbf{P}$ is a permutation matrix, which, when left-multiplied to $\\mathbf{A}$, reorders the rows of $\\mathbf{A}$. \n",
    "  It turns out that all square matrices can be factorized in this form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* If $\\mathbf{A}$ is invertible, then it admits an LU factorization if and only if all its leading principal minors are nonzero. \n",
    "  If $\\mathbf{A}$ is a singular matrix of rank $k$, then it admits an LU factorization if the first $k$ leading principal minors are nonzero\n",
    "\n",
    "* LU decomposition is basically a modified form of Gaussian elimination. We transform the matrix $\\mathbf{A}$ into \n",
    "  an upper triangular matrix $\\mathbf{U}$ by eliminating the entries below the main diagonal. \n",
    "  The **Doolittle algorithm** does the column-by-column elimination, starting from the left, by multiplying $\\mathbf{A}$ to \n",
    "  the left with atomic lower triangular matrices. It results in a *unit* lower triangular matrix and an upper triangular matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Doolittle Algorithm**\n",
    "\n",
    "* We define\n",
    "\n",
    "  >$\\mathbf{A}^{(0)}=\\mathbf{A}$\n",
    "  \n",
    "* We eliminate the matrix elements below the main diagonal in the $k$-th column of $\\mathbf{A}^{(k -1)}$ \n",
    "  by adding to the $i$-th row of this matrix the $k$-th row multiplied by\n",
    "  \n",
    "  >$\\displaystyle l_{i,k}=\\frac{a_{i,k}^{(k-1)}}{a_{k,k}^{(k-1)}}$ $\\text{ for } i=k+1, \\cdots, n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  This can be done by multiplying $\\mathbf{A}^{(k -1)}$ to the left with the lower triangular matrix\n",
    "  \n",
    "  >${\\scriptsize\n",
    "  \\mathbf{L}_k=\n",
    "     \\begin{pmatrix}\n",
    "         1      & 0      &           & \\cdots &        & 0      \\\\ \n",
    "         0      & \\ddots & \\ddots    &        &        &        \\\\ \n",
    "                &        & 1         &        &        &        \\\\ \n",
    "        \\vdots  &        &-l_{k+1,k} &        &        & \\vdots \\\\ \n",
    "                &        & \\vdots    &        & \\ddots & 0      \\\\ \n",
    "         0      &        &-l_{n,k}   &        & 0      & 1\n",
    "     \\end{pmatrix}} \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* We set\n",
    "  \n",
    "  >$\\mathbf{A}^{(k)}=\\mathbf{L}_k\\mathbf{A}^{(k-1)}$, $k=1,\\cdots,n -1$\n",
    "  \n",
    "  After $n -1$ steps, we eliminated all the matrix elements below the main diagonal, \n",
    "  so we obtain an upper triangular matrix $\\mathbf{A}^{(n -1)}$. We find the decomposition\n",
    "  \n",
    "  >$\n",
    "   \\mathbf{A}=\\mathbf{L}_1^{-1}\\mathbf{L}_1\\mathbf{A}^{(0)}=\\mathbf{L}_1^{-1}\\mathbf{A}^{(1)}\n",
    "     =\\mathbf{L}_1^{-1}\\mathbf{L}_2^{-1}\\mathbf{L}_2\\mathbf{A}^{(1)}=\\mathbf{L}_1^{-1}\\mathbf{L}_2^{-1}\\mathbf{A}^{(2)}\n",
    "     =\\cdots=\\mathbf{L}_1^{-1}\\cdots\\mathbf{L}_{n -1}^{-1}\\mathbf{A}^{(n -1)}\n",
    "  $\n",
    "  \n",
    "  Denote the upper triangular matrix $\\mathbf{A}^{(n -1)}$ by $\\mathbf{U}$, and $\\mathbf{L}=\\mathbf{L}_1^{-1}\\cdots\\mathbf{L}_{n -1}^{-1}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uIqhXI3IAOtC",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  Because the inverse of a lower triangular matrix $\\mathbf{L}_k$ is again a lower triangular matrix, \n",
    "  and the multiplication of two lower triangular matrices is again a lower triangular matrix, \n",
    "  it follows that $\\mathbf{L}$ is a lower triangular matrix. Moreover, it can be seen that\n",
    "  \n",
    "  >${\\scriptsize\n",
    "  \\mathbf{L}=\n",
    "     \\begin{pmatrix}\n",
    "         1      & 0      &           & \\cdots &          & 0      \\\\ \n",
    "         l_{2,1}& \\ddots & \\ddots    &        &          &        \\\\ \n",
    "                &        & 1         &        &          &        \\\\ \n",
    "        \\vdots  &        & l_{k+1,k} &        &          & \\vdots \\\\ \n",
    "                &        & \\vdots    &        & 1        & 0      \\\\ \n",
    "         l_{n,1}& \\cdots & l_{n,k}   & \\cdots & l_{n,n-1}& 1\n",
    "     \\end{pmatrix}}  \n",
    "  $\n",
    "  \n",
    "  We obtain $\\mathbf{A}=\\mathbf{L}\\mathbf{U}$\n",
    "  \n",
    "  **NOTE:** It is clear that in order for this algorithm to work, one needs to have $a_{k,k}^{(k-1)}$ at each step \n",
    "  (see the definition of $l_{i,k}$). If this assumption fails at some point, one needs to interchange $k$-th row \n",
    "  with another row below it before continuing. This is why an LU decomposition in general looks like \n",
    "  $\\mathbf{P}\\mathbf{A}=\\mathbf{L}\\mathbf{U}$\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/SeoulTechPSE/EngMath/blob/master/codes/ch08_code4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4kZRVTFAOtD",
    "outputId": "abce374c-e4d8-4a76-b591-9ce1ed034571",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      "array([[ 7.,  3., -1.,  2.],\n",
      "       [ 3.,  8.,  1., -4.],\n",
      "       [-1.,  1.,  4., -1.],\n",
      "       [ 2., -4., -1.,  6.]])\n",
      "\n",
      "P =\n",
      "array([[1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.]])\n",
      "\n",
      "L =\n",
      "array([[ 1.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.42857143,  1.        ,  0.        ,  0.        ],\n",
      "       [-0.14285714,  0.21276596,  1.        ,  0.        ],\n",
      "       [ 0.28571429, -0.72340426,  0.08982036,  1.        ]])\n",
      "\n",
      "U =\n",
      "array([[ 7.        ,  3.        , -1.        ,  2.        ],\n",
      "       [ 0.        ,  6.71428571,  1.42857143, -4.85714286],\n",
      "       [ 0.        ,  0.        ,  3.55319149,  0.31914894],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.88622754]])\n"
     ]
    }
   ],
   "source": [
    "%run ./codes/ch08_code4.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3twS8ABLAOtI",
    "outputId": "8c0165dd-a273-475f-8636-8eb2e4e12d80",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P =\n",
      "array([[1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.]])\n",
      "\n",
      "L =\n",
      "array([[ 1.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.42857143,  1.        ,  0.        ,  0.        ],\n",
      "       [-0.14285714,  0.21276596,  1.        ,  0.        ],\n",
      "       [ 0.28571429, -0.72340426,  0.08982036,  1.        ]])\n",
      "\n",
      "U =\n",
      "array([[ 7.        ,  3.        , -1.        ,  2.        ],\n",
      "       [ 0.        ,  6.71428571,  1.42857143, -4.85714286],\n",
      "       [ 0.        ,  0.        ,  3.55319149,  0.31914894],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.88622754]])\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "from scipy.linalg import lu\n",
    "\n",
    "A = np.array([[7, 3, -1, 2], [3, 8, 1, -4], [-1, 1, 4, -1], [2, -4, -1, 6]], dtype='float64')\n",
    "P, L, U = lu(A)\n",
    "\n",
    "print('P ='); pprint.pprint(P)\n",
    "print('\\nL ='); pprint.pprint(L)\n",
    "print('\\nU ='); pprint.pprint(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Solving Linear Equations**\n",
    "\n",
    "  Given a system of linear equations in matrix form\n",
    "  \n",
    "  >$\\mathbf{A}\\mathbf{x}=\\mathbf{b}$\n",
    "  \n",
    "  Suppose we have already obtained the LUP decomposition of $\\mathbf{A}$ such that \n",
    "  $\\mathbf{P}\\mathbf{A}=\\mathbf{L}\\mathbf{U}$, so $\\mathbf{L}\\mathbf{U}\\mathbf{x}=\\mathbf{P}\\mathbf{b}$\n",
    "  \n",
    "  In this case the solution is done in two logical steps:\n",
    "\n",
    "  * First, we solve the equation $\\mathbf{L}\\mathbf{y}=\\mathbf{P}\\mathbf{b}$ for $\\mathbf{y}$  \n",
    "  * Second, we solve the equation $\\mathbf{U}\\mathbf{x}=\\mathbf{y}$ for $\\mathbf{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U1FSh4p_AOtK",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " \n",
    "  Note that in both cases we are dealing with triangular matrices ($\\mathbf{L}$ and $\\mathbf{U}$), \n",
    "  which can be solved directly by forward and backward substitution without using the Gaussian elimination process \n",
    "  (however we do need this process or equivalent to compute the LU decomposition itself). \n",
    "  The cost of solving a system of linear equations is approximately $\\frac{2}{3}n^{3}$ floating-point operations.\n",
    "    \n",
    "  The above procedure can be repeatedly applied to solve the equation multiple times for different $\\mathbf{b}$. \n",
    "  In this case it is faster (and more convenient) to do an LU decomposition of the matrix $\\mathbf{A}$ \n",
    "  once and then solve the triangular matrices for the different $\\mathbf{b}$, rather than using Gaussian \n",
    "  elimination each time. \n",
    "  The matrices $\\mathbf{L}$ and $\\mathbf{U}$ could be thought to have *encoded* the Gaussian elimination process\n",
    "    \n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/SeoulTechPSE/EngMath/blob/master/codes/ch08_code5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WzVm9dt8AOtK",
    "outputId": "aa158a52-5f24-463a-d9a2-d781f8ad0a4c",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      "array([[ 7.,  3., -1.,  2.],\n",
      "       [ 3.,  8.,  1., -4.],\n",
      "       [-1.,  1.,  4., -1.],\n",
      "       [ 2., -4., -1.,  6.]])\n",
      "\n",
      "b = array([1., 2., 3., 4.])\n",
      "\n",
      "x = array([-1.27619048,  1.87619048,  0.57142857,  2.43809524])\n"
     ]
    }
   ],
   "source": [
    "%run ./codes/ch08_code5.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rwEOUWmqAOtM",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Inverting a Matrix**\n",
    "\n",
    "  In matrix inversion, instead of vector $\\mathbf{b}$, we have matrix $\\mathbf{I}_n$ so that we are trying to find a matrix $\\mathbf{X}$\n",
    "  \n",
    "  >$\\mathbf{L}\\mathbf{U}\\mathbf{X}=\\mathbf{I}_n$\n",
    "  \n",
    "  We can use the same algorithm presented earlier to solve for each column of matrix $\\mathbf{X}$\n",
    "  \n",
    "* **Computing the Determinant**\n",
    "\n",
    "  Given the LUP decomposition $\\mathbf{A}=\\mathbf{P}^{-1}\\mathbf{L}\\mathbf{U}$ of a square matrix $\\mathbf{A}$, \n",
    "  the determinant of $\\mathbf{A}$ can be computed straightforwardly as\n",
    "  \n",
    "  >$\\displaystyle\\mathrm{det}\\,\\mathbf{A}=\\mathrm{det}\\,\\mathbf{P}^{-1}\\,\\mathrm{det}\\,\\mathbf{L}\\,\n",
    "  \\mathrm{det}\\,\\mathbf{U}=(-1)^s \\prod_{i=1}^n l_{ii}\\prod_{i=1}^n u_{ii}$\n",
    "   \n",
    "  where $s$ is the number of row exchanges in the permutation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fof98BqRAOtN",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercises 8.13\n",
    "\n",
    "* 1, 3, 5\n",
    "* 21, 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dv8cYyUMAOtN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.14 Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YwYHzOsjAOtO",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Cryptography**\n",
    "\n",
    "  Cryptography is the study of making *secret writings* or *codes*. We will consider a system of encoding and decoding\n",
    "  messages that requires both the sender and the receiver to know:\n",
    "  \n",
    "  * a specified rule of correspondence between a set of symbols and a set of integers; and \n",
    "  * a specified *nonsingular* matrix $\\mathbf{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-cAewswAOtP",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  **Example:** $\\text{ }$ A correspondence between the twenty-seven integers and the letters of the alphabet and a blank space is given by\n",
    "  \n",
    "  >$\\scriptsize\n",
    "   \\begin{align*}\n",
    "     &\\begin{matrix}\n",
    "       0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 &10 &11 &12 &13 &14 &15 &16 &17 &18 &19 &20 \\\\ \n",
    "       \\text{space} & j & k & l & n & m & s & t & u & w & x & g & h & i & o & p & q & r & v & y & z    \n",
    "      \\end{matrix} \\\\ \n",
    "   & \\\\\n",
    "   &\\;\\text{ }  \n",
    "   \\begin{matrix}\n",
    "       21 &22 &23 &24 &25 &26 \\\\ \n",
    "       a & b & c & d & e & f   \n",
    "     \\end{matrix} \n",
    "   \\end{align*}$\n",
    "  \n",
    "  The numerical equivalent of the message **DR JOHN IS A DOUBLE SPY** is \n",
    "  \n",
    "  > $\\scriptsize\\begin{matrix}\n",
    "        24 & 17 & 0 & 1 & 14 & 12 & 4 & 0 & 13 & 6 & 0 & 21 & 0 & 24 & 14 & 8 & 22 & 3 & 25 & 0 & 6 & 15 & 19\n",
    "      \\end{matrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  The sender will **encode** the message by means of the nonsingular matrix $\\mathbf{A}$ and the receiver will **decode**\n",
    "  the encoded message by means of the matrix $\\mathbf{A}^{-1}$. We choose to write the numerical message as the $3 \\times 8$ matrix\n",
    "  \n",
    "  >$\n",
    "  \\mathbf{M}=\n",
    "    \\left(\\begin{array}{rrrrrrrr}\n",
    "      24 & 17 & 0 & 1 & 14 & 12 & 4 & 0 \\\\ \n",
    "      13 & 6 & 0 & 21 & 0 & 24 & 14 & 8 \\\\ \n",
    "      22 & 3 & 25 & 0 & 6 & 15 & 19 & 0 \n",
    "    \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Note that the last entry $m_{38}$ has been simply padded with a space (the number $0$). A $3 \\times 8$ matrix allows us\n",
    "  to encode the message by means of a $3 \\times 3$ matrix. The encoding matrix $\\mathbf{A}$ is constructed, so that\n",
    "  \n",
    "  * $\\mathbf{A}$ is nonsingular\n",
    "  * $\\mathbf{A}$ has only integer entries, and\n",
    "  * $\\mathbf{A}^{-1}$ has only integer entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  To accomplish the last criterion, we need only select the integer entries of $\\mathbf{A}$ in such a manner that \n",
    "  $\\mathrm{det}\\,\\mathbf{A}=\\pm 1$. We choose\n",
    "      \n",
    "  >$\n",
    "  \\mathbf{A}=\n",
    "    \\left(\\begin{array}{rrr}\n",
    "        -1 & 0 &-1 \\\\\n",
    "        2 & 3 & 4 \\\\\n",
    "        2 & 4 & 5\n",
    "     \\end{array}\\right) \n",
    "  $\n",
    "  \n",
    "  and\n",
    "  \n",
    "  >$\n",
    "  \\mathbf{A}^{-1}=\n",
    "    \\left(\\begin{array}{rrr}\n",
    "        1 & 4 &-3 \\\\\n",
    "        2 & 3 &-2 \\\\\n",
    "       -2 &-4 & 3\n",
    "     \\end{array}\\right)  \n",
    "  $  \n",
    "      \n",
    "  You should verify that $\\mathrm{det}\\,\\mathbf{A}=-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h7Yhk4SUAOtQ",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " The original message is encoded as following:\n",
    "      \n",
    "  >${\\scriptsize\\mathbf{B}=\\mathbf{A}\\mathbf{M}=\n",
    "    \\left(\\begin{array}{rrrrrrrr}\n",
    "     -46 & -20 & -25 & -1 & -20 & -27 & -23 & 0 \\\\ \n",
    "     175 &  64 & 100 & 65 & 52 & 156 & 126 & 24 \\\\ \n",
    "     210 &  73 & 125 & 86 & 58 & 195 & 159 & 32 \n",
    "    \\end{array}\\right)}   \n",
    "  $\n",
    "  \n",
    "  It may be desirable to send the encoded message as letters of the alphabet rather than as numbers. \n",
    "  Thus we rewrite $\\mathbf{B}$ as $\\mathbf{B}'$ using integers modulo 27:\n",
    "  \n",
    "  >${\\scriptsize\\mathbf{B'}=\n",
    "    \\left(\\begin{array}{rrrrrrrr}\n",
    "     8 & 7 & 2 & 26 & 7 & 0 & 4 & 0 \\\\ \n",
    "     13 &  10 & 19 & 11 & 25 & 21 & 18 & 24 \\\\ \n",
    "     21 &  19 & 17 & 5 & 4 & 6 & 24 & 5 \n",
    "    \\end{array}\\right)}   \n",
    "  $ \n",
    "  \n",
    "  The encoded message to be sent in letters is\n",
    "  \n",
    "  > **UTKFT N IXYGEAVDAYRMNSDM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#-- Data for Encoding and Decoding------------------------------------\n",
    "\n",
    "cp = { 0:' ',  1:'j',  2:'k',  3:'l',  4:'n',  5:'m',  6:'s',  7:'t',    \n",
    "       8:'u',  9:'w', 10:'x', 11:'g', 12:'h', 13:'i', 14:'o', 15:'p',  \n",
    "      16:'q', 17:'r', 18:'v', 19:'y', 20:'z', 21:'a', 22:'b', 23:'c', \n",
    "      24:'d', 25:'e', 26:'f' }\n",
    "\n",
    "A = np.array([[-1, 0, -1], [2, 3, 4], [2, 4, 5]])\n",
    "\n",
    "inv_cp =  {v: k for k, v in cp.items()}\n",
    "inv_A = np.rint(np.linalg.inv(A)).astype('int32')\n",
    "\n",
    "#----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_numeric(message):   \n",
    "    return np.array([inv_cp[m] for m in message])\n",
    "\n",
    "def convert_to_letter(numeric_message):\n",
    "    return ''.join([cp[m] for m in numeric_message])\n",
    "\n",
    "def encoding_message(message):  \n",
    "    \n",
    "    numeric_message = convert_to_numeric(message)\n",
    "    \n",
    "    n_app = (3 -len(numeric_message) % 3) % 3\n",
    "    M = np.append(numeric_message, [0]*n_app).reshape(3, -1)\n",
    "    B = np.matmul(A, M) % 27\n",
    "\n",
    "    numeric_message_encoded = B.flatten()\n",
    "    \n",
    "    return convert_to_letter(numeric_message_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BvYj98djAOtT",
    "outputId": "1e7b9346-d068-4e89-99dc-ef956a53640d",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message = DR JOHN IS A DOUBLE SPY\n",
      "Encoded message = UTKFT N IXYGEAVDAYRMNSDM\n"
     ]
    }
   ],
   "source": [
    "message = 'dr john is a double spy'\n",
    "message_encoded = encoding_message(message)\n",
    "\n",
    "print('Message =', message.upper())\n",
    "print('Encoded message =', message_encoded.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fY5wsbQgAOtV",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You should try to imagine the difficulty of decoding the encoded message without prior knowledge. \n",
    "Using the original correspondence and $\\mathbf{A}$, the decoding is the straightforward computation\n",
    "\n",
    "> $\\mathbf{M}=\\mathbf{A}^{-1}\\mathbf{B}'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jcP5Y9YRAOtV",
    "outputId": "db2ca33b-0c02-4e8a-c472-64d137a4b280",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding message = DR JOHN IS A DOUBLE SPY \n"
     ]
    }
   ],
   "source": [
    "def decoding_message(message_encoded):\n",
    "    \n",
    "    B_ = convert_to_numeric(message_encoded).reshape(3, -1)\n",
    "    M_ = np.matmul(inv_A, B_) % 27\n",
    "    \n",
    "    numeric_message_decoded = M_.flatten()\n",
    "    \n",
    "    return convert_to_letter(numeric_message_decoded)\n",
    "\n",
    "message_decoded = decoding_message(message_encoded)\n",
    "\n",
    "print('Decoding message =', message_decoded.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9FtC5LRTAOtX",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **An Error-Correcting Code**\n",
    "\n",
    "  We are going to examine briefly the concept of digital communication, say, communication between \n",
    "  a satellite and a computer.\n",
    "  As a result, we will deal only with matrices whose entries are binary digits, namely $0$s and $1$s. \n",
    "  When addng and multipying such matrices,\n",
    "  we will use arithmetic modulo 2. This arithmetic is defined by the addition and multiplication tables\n",
    "\n",
    "\n",
    ">| + | 0 | 1 |\n",
    "|---|---|---| \n",
    "| **0** | 0 | 1 |\n",
    "| **1** | 1 |<font color='red'> 0 </font>|\n",
    "\n",
    ">| x | 0 | 1 |\n",
    "|---|---|---| \n",
    "| **0** | 0 | 0 |\n",
    "| **1** | 0 | 1 |   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* In digital communication the messages or words are binary $n$-tuples. An $n$-bit word is also said \n",
    "  to be a binary string of length $n$. By **encoding** a message, we mean a process whereby we transform\n",
    "  a word $\\mathbf{W}$ of length $n$ into another word $\\mathbf{C}$ of length $n +m$ by augmenting $\\mathbf{W}$\n",
    "  with $m$ additional bits, called **parity check bits**. An encoding/decoding scheme is called a **code**\n",
    "  \n",
    "  The **Hamming (7, 4) code** is an encoding/decoding scheme that can detect the presence of a single error\n",
    "  in a received message and can tell which bit must be corrected. In $(7, 4)$ code the encoding process\n",
    "  consists of transforming a 4-bit word \n",
    "  \n",
    "  >$\\mathbf{W}=\\begin{bmatrix} w_1 & w_2 & w_3 & w_4 \\end{bmatrix}$\n",
    "  \n",
    "  into a 7-bit code word\n",
    "  \n",
    "  >$\\mathbf{C}=\\begin{bmatrix} \\mathbf{c_1} & \\mathbf{c_2} & w_1 & \\mathbf{c_3} & w_2 & w_3 & w_4 \\end{bmatrix}$\n",
    "  \n",
    "  where $c_1$, $c_2$, and $c_3$ denote the parity check bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " and are defined in terms of the information bits $w_1$, $w_2$, $w_3$, and $w_4$\n",
    "  \n",
    "  >$\n",
    "    \\begin{align*}\n",
    "        c_1 &= w_1 +w_2 +w_4\\\\ \n",
    "        c_2 &= w_1 +w_3 +w_4\\\\ \n",
    "        c_3 &= w_2 +w_3 +w_4\n",
    "    \\end{align*} \\;\\;\\;\\;\\;\\text{(C1)} \n",
    "  $ \n",
    "  \n",
    "  We first observe that in modulo 2 arithmatic there are no negative numbers; the additive inverse\n",
    "  is $1$, not $-1$. With this in mind, we can write the system $\\text{(C1)}$ in the equivalent form\n",
    "  \n",
    "  >$\n",
    "    \\begin{align*}\n",
    "        c_3 &+ w_2 +w_3 +w_4 = 0\\\\\n",
    "        c_2 &+ w_1 +w_3 +w_4 = 0\\\\        \n",
    "        c_1 &+ w_1 +w_2 +w_4 = 0 \n",
    "    \\end{align*} \\;\\;\\;\\;\\; \\text{(C2)}   \n",
    "  $ \n",
    "  \n",
    "  These are called **parity check equations**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " As a matrix product, $\\text{(C2)}$ can be written\n",
    "  \n",
    "  >$\\mathbf{H}\\mathbf{C}^T=\\mathbf{0}$\n",
    "  \n",
    "  where \n",
    "  \n",
    "  >$\\mathbf{H}=\n",
    "    \\begin{pmatrix}\n",
    "        0 & 0 & 0 & 1 & 1 & 1 & 1\\\\ \n",
    "        0 & 1 & 1 & 0 & 0 & 1 & 1\\\\\n",
    "        1 & 0 & 1 & 0 & 1 & 0 & 1\n",
    "    \\end{pmatrix}$\n",
    "  \n",
    "  is called the **parity check matrix**. A closer inspection of $\\mathbf{H}$ shows \n",
    "  a surprising fact: The columns of $\\mathbf{H}$, left to right, are \n",
    "  the numbers $1$ through $7$ written in binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  Let $\\mathbf{R}$ be a $1 \\times 7$ matrix representing the received message. The product\n",
    "  \n",
    "  >$\\mathbf{S}=\\mathbf{H}\\mathbf{R}^T$\n",
    "  \n",
    "  is called the **syndome** of $\\mathbf{R}$. If $\\mathbf{S}=\\mathbf{0}$, it is assumed that\n",
    "  the transmission is correct and that $\\mathbf{R}$ is the same as the original encoded \n",
    "  message $\\mathbf{C}$. The decoding of the message is accomplished by simply dropping the \n",
    "  three check bits in $\\mathbf{R}$\n",
    "  \n",
    "  Let \n",
    "  \n",
    "  >$\\mathbf{E}=\\begin{bmatrix} e_1 & e_2 & e_3 & e_4 & e_5 & e_6 & e_7 \\end{bmatrix}$\n",
    "  \n",
    "  be a *single-error noise* word added to $\\mathbf{C}$ during its transmission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8jTthgvcAOtY",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  If noise changes the $i$-th bit, $e_i=1$. The received message is then \n",
    "  $\\mathbf{R}=\\mathbf{C}+\\mathbf{E}$. We see that\n",
    "  \n",
    "  >$\\begin{align*}\n",
    "     \\mathbf{S}&=\\mathbf{H}\\mathbf{R}^T\n",
    "            =\\mathbf{H}(\\mathbf{C}^T +\\mathbf{E}^T)=\\mathbf{H}\\mathbf{E}^T\\\\\n",
    "        &= e_1 \\begin{pmatrix} 0\\\\ 0\\\\ 1\\end{pmatrix}\n",
    "          +e_2 \\begin{pmatrix} 0\\\\ 1\\\\ 0\\end{pmatrix}\n",
    "          +e_3 \\begin{pmatrix} 0\\\\ 1\\\\ 1\\end{pmatrix}\n",
    "          +e_4 \\begin{pmatrix} 1\\\\ 0\\\\ 0\\end{pmatrix}\n",
    "          +e_5 \\begin{pmatrix} 1\\\\ 0\\\\ 1\\end{pmatrix} \n",
    "          +e_6 \\begin{pmatrix} 1\\\\ 1\\\\ 0\\end{pmatrix}\n",
    "          +e_7 \\begin{pmatrix} 1\\\\ 1\\\\ 1\\end{pmatrix}           \n",
    "    \\end{align*}    \n",
    "   $\n",
    "   \n",
    "   Hence, if $\\mathbf{S}\\neq\\mathbf{0}$, then $\\mathbf{S}$ must be one of \n",
    "   the columns of $\\mathbf{H}$. If $\\mathbf{R}$ contains a single error, we see that\n",
    "   the syndrome itself indicates which bit is in error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Method of Least Squares**\n",
    "\n",
    "  ><img src=\"figures/ch08_figure06.png\" width=\"350\">\n",
    "\n",
    "  When performing experiments we often tabulate data in the form of ordered pairs $(x_1, y_1)$,\n",
    "  $(x_2, y_2)$, $\\cdots$, $(x_n, y_n)$, with each $x_i$ distinct. Given the data, it is then often\n",
    "  desirable to predict $y$ from $x$ by finding a mathematical model, that is, \n",
    "  a function $f(x)$ that approximates or fits the data\n",
    "  \n",
    "  We shall confine our attention to the problem of finding a linear polynomial\n",
    "  $f(x)=ax +b$ that best fits the data $(x_i, y_i)$, $i=1,\\cdots, n$. The procedure\n",
    "  for finding this linear function is known as **the method of least squares**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  One way to determine how well the linear function $f(x)=ax +b$ fits the data is to\n",
    "  measure the vertical distances between the data points $y_i$ and the graphs $f(x_i)$\n",
    "  \n",
    "  >$e_i=|y_i -f(x_i)|$, $\\;i=1,\\cdots, n$\n",
    "  \n",
    "  An actual approach is to find a linear function $f$ so that\n",
    "  the sum of the *squares* of all the $e_i$ values is a minimum\n",
    "  \n",
    "  >$\\displaystyle\\min_{a, \\,b} E=\\min_{a, \\,b} \\sum_{i=1}^n \\left[y_i -ax_i -b\\right]^2$\n",
    "  \n",
    "  Then to find the minimum value of $E$, we set the first partial derivatives with respect to\n",
    "  $a$ and $b$ to zero:\n",
    "  \n",
    "  >$\\displaystyle \\frac{\\partial E}{\\partial a}=0 \\;\\text{ and }\\; \\frac{\\partial E}{\\partial b}=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  The last two conditions yield, in turn,\n",
    "  \n",
    "  >$\n",
    "    \\begin{align*}\n",
    "        -2 \\sum_{i=1}^n x_i [y_i -a x_i -b] &= 0\\\\ \n",
    "        -2 \\sum_{i=1}^n [y_i -a x_i -b] &= 0\n",
    "    \\end{align*}  \n",
    "  $\n",
    "\n",
    "  Expanding the sums and rearranging, we find the above system is the same as\n",
    "  \n",
    "  >$\n",
    "    \\begin{pmatrix}\n",
    "     \\displaystyle\\sum_{i=1}^n x_i^2 & \\displaystyle\\sum_{i=1}^n x_i\\\\ \n",
    "     \\displaystyle\\sum_{i=1}^n x_i   & n\n",
    "    \\end{pmatrix}\n",
    "    \\begin{pmatrix}\n",
    "      a \\\\ b\n",
    "    \\end{pmatrix}=\n",
    "    \\begin{pmatrix}\n",
    "     \\displaystyle \\sum_{i=1}^n x_i y_i\\\\ \\displaystyle \\sum_{i=1}^n y_i \\;\\;\\;\n",
    "    \\end{pmatrix}  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o8RTTNBfAOtZ",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "  and, in terms of matrices, is  equivalent to \n",
    "  \n",
    "  >$\\mathbf{A}^T\\mathbf{A}\\mathbf{x}=\\mathbf{A}^T\\mathbf{b}$\n",
    "  \n",
    "  where\n",
    "  \n",
    "  >$\n",
    "    \\mathbf{A}=\n",
    "    \\begin{pmatrix}\n",
    "     x_1 & 1\\\\ \n",
    "     x_2 & 1\\\\ \n",
    "     \\vdots & \\vdots\\\\ \n",
    "     x_n & 1 \n",
    "    \\end{pmatrix},\n",
    "    \\;\\mathbf{b}=\n",
    "    \\begin{pmatrix}\n",
    "     y_1\\\\\n",
    "     y_2\\\\ \n",
    "     \\vdots\\\\ \n",
    "     y_n\n",
    "    \\end{pmatrix},\n",
    "    \\;\\mathbf{x}=\n",
    "    \\begin{pmatrix}\n",
    "     a \\\\ b\n",
    "    \\end{pmatrix}\n",
    "    \\;\\;\\text{(LS)}\n",
    "  $ \n",
    "  \n",
    "  Unless the data points all lie on the same vertical line, the matrix $\\mathbf{A}^T\\mathbf{A}$\n",
    "  is nonsingular. Thus $\\text{(LS)}$ has the unique solution\n",
    "  \n",
    "  >$\n",
    "    \\mathbf{x} =\\left(\\mathbf{A}^T \\mathbf{A} \\right)^T \\mathbf{A}^T \\mathbf{b}\n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XkM51c3nAOta",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example** $\\text{ }$ Nonlinear Least Squares: $\\text{ } f(x) = 2.5e^{-1.3x}$\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/SeoulTechPSE/EngMath/blob/master/codes/ch08_code6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LdIPnmm_AOtb",
    "outputId": "f3179fd1-d8b1-42c3-b4db-e999a0ad665b",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ./codes/ch08_code6.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Discrete Compartmental Models**\n",
    "\n",
    "  Strontium 90 is deposited into pastureland by rainfall. To study how this material is \n",
    "  cycled through the ecosystem, we divide the system into the compartments shown in the following\n",
    "\n",
    "  ><img src=\"figures/ch08_figure07.png\" width=\"600\">\n",
    "  \n",
    "  Suppose that $\\Delta t=1$ month and the transfer coefficients (which have been estimated\n",
    "  experimentally) shown in the figure are measured in fraction/month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pw0VG2fDAOtd",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " Suppose that rainfall has\n",
    "  deposited the strotium 90 into the compartments so that\n",
    "  \n",
    "  >$\\mathbf{x}_0=\n",
    "   \\begin{pmatrix}\n",
    "    20\\\\ \n",
    "    60\\\\ \n",
    "    15\\\\ \n",
    "    20\n",
    "   \\end{pmatrix}$\n",
    "   \n",
    "  Units might be grams per hectare. Compute the states of the ecosystem over the next 12 months\n",
    "  \n",
    "  *Solution* From the data in figure, we see that transfer matrix $\\mathbf{T}$ is\n",
    "  \n",
    "  >$\\scriptsize\n",
    "    \\mathbf{T}=\n",
    "    \\begin{pmatrix}\n",
    "     0.85 & 0.01 & 0   & 0 \\\\ \n",
    "     0.05 & 0.98 & 0.2 & 0 \\\\ \n",
    "     0.1  & 0    & 0.8 & 0 \\\\ \n",
    "     0    & 0.01 & 0   & 1\n",
    "    \\end{pmatrix}  \n",
    "  $\n",
    "  \n",
    "  We must compute $\\mathbf{x}_1$, $\\mathbf{x}_2$, $\\cdots$, $\\mathbf{x}_{12}$ by using\n",
    "  the recursion formula $\\mathbf{x}_{n+1}=\\mathbf{T}\\mathbf{x}_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eB5SOiudAOtd",
    "outputId": "e9217c98-072a-40a1-d6f5-ea776a276c20",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Month     Grasses   Soil      Dead_OM   Streams\n",
      "-----------------------------------------------\n",
      "    0     20.00     60.00     15.00     20.00\n",
      "    1     17.60     62.80     14.00     20.60\n",
      "    2     15.59     65.22     12.96     21.23\n",
      "    3     13.90     67.29     11.93     21.88\n",
      "    4     12.49     69.03     10.93     22.55\n",
      "    5     11.31     70.46      9.99     23.24\n",
      "    6     10.32     71.61      9.13     23.95\n",
      "    7      9.48     72.52      8.33     24.66\n",
      "    8      8.79     73.21      7.61     25.39\n",
      "    9      8.20     73.71      6.97     26.12\n",
      "   10      7.71     74.04      6.40     26.86\n",
      "   11      7.29     74.22      5.89     27.60\n",
      "   12      6.94     74.28      5.44     28.34\n"
     ]
    }
   ],
   "source": [
    "T = np.array([[0.85, 0.01, 0.00, 0.00], \n",
    "              [0.05, 0.98, 0.20, 0.00],\n",
    "              [0.10, 0.00, 0.80, 0.00], \n",
    "              [0.00, 0.01, 0.00, 1.00]])\n",
    "x = np.array([20, 60, 15, 20]).T\n",
    "\n",
    "print('-' *47)\n",
    "print('Month     Grasses   Soil      Dead_OM   Streams')\n",
    "print('-' *47)\n",
    "for month in range(13):   \n",
    "    print('%5d %9.2f %9.2f %9.2f %9.2f' % (month, x[0], x[1], x[2], x[3]))  \n",
    "    x = np.matmul(T, x)  "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "include_colab_link": true,
   "name": "ch08.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
